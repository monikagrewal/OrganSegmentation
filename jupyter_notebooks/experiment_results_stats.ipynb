{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['robust-teacher-robust-student-iter3-folds', 'robust-teacher-robust-student-iter2-folds', 'good-baseline-folds-noisy-data_05122022_160609', 'good-baseline-folds-32', 'basic-teacher-basic-student-folds', 'robust-teacher-folds_05122022_161207', 'robust-teacher-robust-student-folds', 'basic-teacher-folds-32', 'basic-teacher-robust-student-folds_02122022']\n"
     ]
    }
   ],
   "source": [
    "metrics  = ['dice', 'sd', 'hd']\n",
    "basepath='/export/scratch3/grewal/OAR_segmentation/runs/final_experiments_new'\n",
    "print(os.listdir(basepath))\n",
    "experiments_info = OrderedDict({'unet-noisy': 'good-baseline-folds-noisy-data_05122022_160609',\n",
    "                    'unet': 'good-baseline-folds-32',\n",
    "                    'basic-teacher': 'basic-teacher-folds-32',\n",
    "                    'basic-student': 'basic-teacher-basic-student-folds',\n",
    "                    'robust-teacher': 'robust-teacher-folds_05122022_161207',\n",
    "                    'robust-student': 'basic-teacher-robust-student-folds_02122022',\n",
    "                    'robust-teacher-robust-student': 'robust-teacher-robust-student-folds',\n",
    "                    'robust-teacher-robust-student - iter2': 'robust-teacher-robust-student-iter2-folds',\n",
    "                    'robust-teacher-robust-student - iter3': 'robust-teacher-robust-student-iter3-folds',\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_all_folds(experiment_path):\n",
    "    \"\"\"This function retrieves the test results located in test_postprocess and \n",
    "    returns the averages performance per organ and overall.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    all_df = []\n",
    "    for filepath in glob.glob(experiment_path + '/*/*/test_postprocess/*.csv'):\n",
    "        df = pd.read_csv(filepath)\n",
    "        all_df.append(df)\n",
    "\n",
    "    all_df = pd.concat(all_df, axis=0)\n",
    "    # remove background\n",
    "    all_df = all_df.loc[:, ~all_df.columns.str.contains('background')]\n",
    "    # remove 'present labels' and 'mean_dice'\n",
    "    all_df = all_df.drop(['present labels', 'mean_dice'], axis=1)\n",
    "    return all_df\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OAR wise metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dice_bowel_bag  dice_bladder  dice_hip  dice_rectum  sd_bowel_bag  \\\n",
      "mean        0.794705      0.892514  0.915695     0.735790      0.615531   \n",
      "std         0.112442      0.160511  0.037321     0.139310      0.107703   \n",
      "mean        0.847657      0.902419  0.919086     0.731505      0.663699   \n",
      "std         0.067057      0.156189  0.022342     0.153214      0.092677   \n",
      "mean        0.848819      0.906114  0.918095     0.741524      0.664528   \n",
      "\n",
      "      sd_bladder    sd_hip  sd_rectum  hd_bowel_bag  hd_bladder     hd_hip  \\\n",
      "mean    0.882371  0.966181   0.745053     35.273295    7.835055   4.164103   \n",
      "std     0.169874  0.047100   0.149898     24.767987   10.514225  20.143955   \n",
      "mean    0.900714  0.970312   0.745246     19.343290    9.681867   2.933217   \n",
      "std     0.163579  0.032738   0.155091     11.699754   37.379887   1.002871   \n",
      "mean    0.905482  0.968602   0.754598     18.434255    7.959590   2.948901   \n",
      "\n",
      "      hd_rectum experiment_name  \n",
      "mean  16.979613      unet-noisy  \n",
      "std   11.862211      unet-noisy  \n",
      "mean  17.797952            unet  \n",
      "std   13.260110            unet  \n",
      "mean  17.100827   basic-teacher  \n"
     ]
    }
   ],
   "source": [
    "all_df = []\n",
    "for experiment_name, experiment_path in experiments_info.items():\n",
    "    experiment_fullpath = os.path.join(basepath, experiment_path)\n",
    "    df = concat_all_folds(experiment_fullpath)\n",
    "\n",
    "    # filter metrics\n",
    "    all_metrics = []\n",
    "    for metric in metrics:\n",
    "        all_metrics.append(df.filter(like=metric))\n",
    "    \n",
    "    df_metrics = pd.concat(all_metrics, axis=1)\n",
    "\n",
    "    # describe\n",
    "    df_summary = df_metrics.describe().loc[[\"mean\", \"std\"], :]\n",
    "    df_summary[\"experiment_name\"] = experiment_name\n",
    "\n",
    "    all_df.append(df_summary)\n",
    "\n",
    "df = pd.concat(all_df, axis=0)\n",
    "print(df.head())\n",
    "df.to_csv(\"../outputs/results_table.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## per scan mean metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet-noisy & 0.7947 (0.1124) & 0.8925 (0.1605) & 0.9157 (0.0373) & 0.7358 (0.1393) & 0.6155 (0.1077) & 0.8824 (0.1699) & 0.9662 (0.0471) & 0.7451 (0.1499) & 35.2733 (24.768) & 7.8351 (10.5142) & 4.1641 (20.144) & 16.9796 (11.8622) \\\n",
      "unet & 0.8477 (0.0671) & 0.9024 (0.1562) & 0.9191 (0.0223) & 0.7315 (0.1532) & 0.6637 (0.0927) & 0.9007 (0.1636) & 0.9703 (0.0327) & 0.7452 (0.1551) & 19.3433 (11.6998) & 9.6819 (37.3799) & 2.9332 (1.0029) & 17.798 (13.2601) \\\n",
      "basic-teacher & 0.8488 (0.0621) & 0.9061 (0.1459) & 0.9181 (0.025) & 0.7415 (0.1405) & 0.6645 (0.0868) & 0.9055 (0.1561) & 0.9686 (0.0384) & 0.7546 (0.141) & 18.4343 (9.9719) & 7.9596 (26.749) & 2.9489 (1.0336) & 17.1008 (12.607) \\\n",
      "basic-student & 0.8631 (0.0559) & 0.9213 (0.1143) & 0.9265 (0.0214) & 0.7695 (0.1263) & 0.6891 (0.0857) & 0.9313 (0.1197) & 0.9755 (0.0318) & 0.7896 (0.1292) & 17.2601 (10.4694) & 6.3063 (22.6983) & 2.8656 (1.0433) & 16.1102 (18.3493) \\\n",
      "robust-teacher & 0.8469 (0.0701) & 0.9023 (0.1543) & 0.9173 (0.024) & 0.7458 (0.127) & 0.6609 (0.0884) & 0.9046 (0.1625) & 0.968 (0.0347) & 0.7586 (0.1259) & 18.4266 (10.8334) & 7.5583 (22.3047) & 2.9481 (1.053) & 17.336 (17.8596) \\\n",
      "robust-student & 0.8586 (0.0557) & 0.9208 (0.1003) & 0.9262 (0.0219) & 0.7786 (0.1196) & 0.6833 (0.0861) & 0.9295 (0.1043) & 0.9753 (0.0323) & 0.8024 (0.121) & 17.5527 (10.2298) & 5.5704 (15.119) & 2.8684 (1.0471) & 15.5799 (17.9968) \\\n",
      "robust-teacher-robust-student & 0.8625 (0.0554) & 0.9193 (0.1058) & 0.9234 (0.0222) & 0.781 (0.1099) & 0.6897 (0.084) & 0.9274 (0.1078) & 0.9729 (0.0334) & 0.803 (0.1137) & 17.0958 (11.2297) & 5.1202 (7.2187) & 2.9011 (1.0758) & 14.569 (10.626) \\\n",
      "robust-teacher-robust-student - iter2 & 0.8612 (0.055) & 0.9239 (0.0888) & 0.9269 (0.0216) & 0.7839 (0.1192) & 0.691 (0.0826) & 0.9357 (0.0944) & 0.975 (0.0321) & 0.8101 (0.1195) & 17.2335 (10.7405) & 4.7109 (6.549) & 2.8823 (1.0766) & 14.5822 (11.2877) \\\n",
      "robust-teacher-robust-student - iter3 & 0.864 (0.0554) & 0.9231 (0.076) & 0.9276 (0.0223) & 0.7792 (0.1268) & 0.6958 (0.0832) & 0.9326 (0.0855) & 0.9752 (0.033) & 0.8059 (0.1261) & 17.4133 (11.7638) & 4.4937 (5.2203) & 2.8829 (1.1448) & 15.0496 (11.9427) \\\n"
     ]
    }
   ],
   "source": [
    "# make latex table\n",
    "for i in range(0, len(df), 2):\n",
    "    mean = df.iloc[i].to_list()[:-1]\n",
    "    mean = [str(np.round(item, 4)) for item in mean]\n",
    "    std = df.iloc[i+1].to_list()[:-1]\n",
    "    std = [str(np.round(item, 4)) for item in std]\n",
    "    entry_list = [f\"& {item1} ({item2}) \" for item1, item2 in zip(mean, std)]\n",
    "    entry_str = \"\".join(entry_list)\n",
    "\n",
    "    experiment_name = df.iloc[i].to_list()[-1]\n",
    "    entry_str = experiment_name +  \" \" + entry_str + '\\\\'\n",
    "    print(entry_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = []\n",
    "for experiment_name, experiment_path in experiments_info.items():\n",
    "    experiment_fullpath = os.path.join(basepath, experiment_path)\n",
    "    df = concat_all_folds(experiment_fullpath)\n",
    "\n",
    "    # all metrics average over OARs\n",
    "    mean_metrics = {}\n",
    "    for metric in metrics:\n",
    "        mean_metrics[f\"{metric}\"] = df.filter(like=metric).mean(axis=1)\n",
    "\n",
    "    df_metrics = pd.DataFrame.from_dict(mean_metrics)\n",
    "    df_metrics[\"experiment_name\"] = experiment_name\n",
    "    all_df.append(df_metrics)\n",
    "\n",
    "df = pd.concat(all_df, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>dice</th>\n",
       "      <th>hd</th>\n",
       "      <th>sd</th>\n",
       "      <th>experiment_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>5.77250</td>\n",
       "      <td>0.85875</td>\n",
       "      <td>basic-student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8725</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>13.71775</td>\n",
       "      <td>0.78775</td>\n",
       "      <td>basic-student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9125</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>9.18400</td>\n",
       "      <td>0.86400</td>\n",
       "      <td>basic-student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>5.25900</td>\n",
       "      <td>0.91500</td>\n",
       "      <td>basic-student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.8925</td>\n",
       "      <td>7.69800</td>\n",
       "      <td>0.89125</td>\n",
       "      <td>basic-student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  recall    dice        hd       sd experiment_name\n",
       "0     0.8875  0.8650  0.8600   5.77250  0.85875   basic-student\n",
       "1     0.8725  0.8600  0.8600  13.71775  0.78775   basic-student\n",
       "2     0.9125  0.8825  0.8950   9.18400  0.86400   basic-student\n",
       "3     0.8850  0.9725  0.9300   5.25900  0.91500   basic-student\n",
       "4     0.9175  0.8850  0.8925   7.69800  0.89125   basic-student"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## describe and normality test\n",
    "### We do Kolmogorov-Smirnov test because N>50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet-noisy\n",
      "          dice        sd         hd\n",
      "mean  0.834676  0.802284  16.063017\n",
      "std   0.061577  0.068164   9.067847\n",
      "\n",
      "unet\n",
      "          dice        sd         hd\n",
      "mean  0.850167  0.819993  12.439081\n",
      "std   0.059150  0.065504  10.584513\n",
      "\n",
      "basic-teacher\n",
      "          dice        sd         hd\n",
      "mean  0.853638  0.823302  11.610893\n",
      "std   0.055356  0.061791   7.940141\n",
      "\n",
      "basic-student\n",
      "          dice        sd         hd\n",
      "mean  0.870086  0.846372  10.635553\n",
      "std   0.046246  0.051777   7.996050\n",
      "\n",
      "robust-teacher\n",
      "          dice        sd         hd\n",
      "mean  0.853086  0.823047  11.567255\n",
      "std   0.052472  0.057154   7.727776\n",
      "\n",
      "robust-student\n",
      "         dice        sd         hd\n",
      "mean  0.87109  0.847620  10.392840\n",
      "std   0.04275  0.048497   6.675385\n",
      "\n",
      "robust-teacher-robust-student\n",
      "          dice        sd        hd\n",
      "mean  0.871571  0.848246  9.921549\n",
      "std   0.041884  0.046790  4.715523\n",
      "\n",
      "robust-teacher-robust-student - iter2\n",
      "          dice        sd        hd\n",
      "mean  0.873995  0.852945  9.852228\n",
      "std   0.041282  0.046036  4.861616\n",
      "\n",
      "robust-teacher-robust-student - iter3\n",
      "          dice        sd        hd\n",
      "mean  0.873481  0.852385  9.959882\n",
      "std   0.041014  0.046281  4.842770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for experiment_name in experiments_info.keys():\n",
    "    print(experiment_name)\n",
    "    df_experiment = df.loc[df[\"experiment_name\"]==experiment_name]\n",
    "    print(df_experiment.describe().loc[[\"mean\", \"std\"], :])\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "# for experiment_name in experiments_info.keys():\n",
    "#     print(experiment_name)\n",
    "#     df_experiment = df.loc[df[\"experiment_name\"]==experiment_name]\n",
    "#     # kstest\n",
    "#     for metric in metrics:\n",
    "#         x = df_experiment.loc[:, metric].values\n",
    "#         ks_result = stats.ks_1samp(x, stats.norm.cdf)\n",
    "#         print(metric, ks_result)\n",
    "#     print(\"\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distributions not normal, so Friedman's test for main effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision\n",
      "FriedmanchisquareResult(statistic=16.05325329202224, pvalue=0.0011058295831555085)\n",
      "\n",
      "recall\n",
      "FriedmanchisquareResult(statistic=408.57903879560035, pvalue=3.0677939118411136e-88)\n",
      "\n",
      "dice\n",
      "FriedmanchisquareResult(statistic=256.94183095842305, pvalue=2.062188102852081e-55)\n",
      "\n",
      "hd\n",
      "FriedmanchisquareResult(statistic=73.88942031758283, pvalue=6.267728008645628e-16)\n",
      "\n",
      "sd\n",
      "FriedmanchisquareResult(statistic=267.0085927057482, pvalue=1.3697488436069074e-57)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"dice\", \"hd\", \"sd\"]\n",
    "for metric in metrics:\n",
    "    data = []\n",
    "    for experiment_name in experiments_info.keys():\n",
    "        x = df.loc[df.experiment_name==experiment_name, metric].values\n",
    "        data.append(x)\n",
    "    \n",
    "    test_stat = stats.friedmanchisquare(*data)\n",
    "    print(metric)\n",
    "    print(test_stat)\n",
    "    print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### significant main effect in all metrics, so wilcoxon signed rank test for post-hoc comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dice\n",
      "basic-student vs. robust-teacher WilcoxonResult(statistic=23161.5, pvalue=1.80360512459764e-36)\n",
      "basic-student vs. robust-teacher-robust-student WilcoxonResult(statistic=60722.0, pvalue=0.718460130921065)\n",
      "basic-student vs. robust-student WilcoxonResult(statistic=60930.5, pvalue=0.6538551549722539)\n",
      "basic-student vs. unet-noisy WilcoxonResult(statistic=10994.5, pvalue=6.41158955300171e-61)\n",
      "basic-student vs. unet WilcoxonResult(statistic=22854.5, pvalue=4.5126471640319576e-38)\n",
      "basic-student vs. basic-teacher WilcoxonResult(statistic=20046.5, pvalue=2.20615275903994e-41)\n",
      "robust-teacher vs. robust-teacher-robust-student WilcoxonResult(statistic=17704.0, pvalue=4.3389033085445e-46)\n",
      "robust-teacher vs. robust-student WilcoxonResult(statistic=22318.5, pvalue=1.553205221617875e-38)\n",
      "robust-teacher vs. unet-noisy WilcoxonResult(statistic=34556.5, pvalue=1.5302008162909071e-21)\n",
      "robust-teacher vs. unet WilcoxonResult(statistic=62780.5, pvalue=0.7950701554635415)\n",
      "robust-teacher vs. basic-teacher WilcoxonResult(statistic=62634.0, pvalue=0.7607084230850797)\n",
      "robust-teacher-robust-student vs. robust-student WilcoxonResult(statistic=60533.5, pvalue=0.7317280865495819)\n",
      "robust-teacher-robust-student vs. unet-noisy WilcoxonResult(statistic=10344.5, pvalue=1.0507686386737963e-62)\n",
      "robust-teacher-robust-student vs. unet WilcoxonResult(statistic=21157.0, pvalue=1.6026995462517557e-40)\n",
      "robust-teacher-robust-student vs. basic-teacher WilcoxonResult(statistic=22506.0, pvalue=3.976033728543741e-37)\n",
      "robust-student vs. unet-noisy WilcoxonResult(statistic=10417.0, pvalue=5.9170192660476e-63)\n",
      "robust-student vs. unet WilcoxonResult(statistic=21926.5, pvalue=5.557080128389612e-39)\n",
      "robust-student vs. basic-teacher WilcoxonResult(statistic=18434.5, pvalue=1.622796266309163e-44)\n",
      "unet-noisy vs. unet WilcoxonResult(statistic=37787.5, pvalue=5.95782817019717e-18)\n",
      "unet-noisy vs. basic-teacher WilcoxonResult(statistic=32358.5, pvalue=2.4436702394832398e-24)\n",
      "unet vs. basic-teacher WilcoxonResult(statistic=58757.5, pvalue=0.1362848281021002)\n",
      "\n",
      "hd\n",
      "basic-student vs. robust-teacher WilcoxonResult(statistic=46510.5, pvalue=2.866882573006051e-10)\n",
      "basic-student vs. robust-teacher-robust-student WilcoxonResult(statistic=60594.5, pvalue=0.022014158269112665)\n",
      "basic-student vs. robust-student WilcoxonResult(statistic=67949.0, pvalue=0.9903686484973812)\n",
      "basic-student vs. unet-noisy WilcoxonResult(statistic=15981.0, pvalue=1.4779717507584463e-52)\n",
      "basic-student vs. unet WilcoxonResult(statistic=40569.5, pvalue=1.5098289019453412e-15)\n",
      "basic-student vs. basic-teacher WilcoxonResult(statistic=42429.5, pvalue=6.914961404517397e-14)\n",
      "robust-teacher vs. robust-teacher-robust-student WilcoxonResult(statistic=35488.5, pvalue=1.3100083137925029e-20)\n",
      "robust-teacher vs. robust-student WilcoxonResult(statistic=46895.5, pvalue=2.7954210049366945e-10)\n",
      "robust-teacher vs. unet-noisy WilcoxonResult(statistic=24000.5, pvalue=2.3210162548871373e-38)\n",
      "robust-teacher vs. unet WilcoxonResult(statistic=62131.5, pvalue=0.08833445978555618)\n",
      "robust-teacher vs. basic-teacher WilcoxonResult(statistic=66177.0, pvalue=0.6505239273759656)\n",
      "robust-teacher-robust-student vs. robust-student WilcoxonResult(statistic=58228.0, pvalue=0.00685461107340246)\n",
      "robust-teacher-robust-student vs. unet-noisy WilcoxonResult(statistic=12270.5, pvalue=1.7207212394419465e-59)\n",
      "robust-teacher-robust-student vs. unet WilcoxonResult(statistic=34875.5, pvalue=1.4258425231531554e-22)\n",
      "robust-teacher-robust-student vs. basic-teacher WilcoxonResult(statistic=37708.5, pvalue=1.9919963743172716e-18)\n",
      "robust-student vs. unet-noisy WilcoxonResult(statistic=13212.5, pvalue=8.773545965007716e-58)\n",
      "robust-student vs. unet WilcoxonResult(statistic=40570.0, pvalue=6.40054018307493e-16)\n",
      "robust-student vs. basic-teacher WilcoxonResult(statistic=39704.0, pvalue=4.541384428922949e-16)\n",
      "unet-noisy vs. unet WilcoxonResult(statistic=29896.5, pvalue=2.1766054394839557e-29)\n",
      "unet-noisy vs. basic-teacher WilcoxonResult(statistic=25290.5, pvalue=4.494314232281302e-36)\n",
      "unet vs. basic-teacher WilcoxonResult(statistic=61409.5, pvalue=0.03993549803753605)\n",
      "\n",
      "sd\n",
      "basic-student vs. robust-teacher WilcoxonResult(statistic=23355.5, pvalue=3.366282841940865e-39)\n",
      "basic-student vs. robust-teacher-robust-student WilcoxonResult(statistic=65378.0, pvalue=0.3645756609744878)\n",
      "basic-student vs. robust-student WilcoxonResult(statistic=66563.5, pvalue=0.4768171897352639)\n",
      "basic-student vs. unet-noisy WilcoxonResult(statistic=9896.0, pvalue=1.1581366580160869e-64)\n",
      "basic-student vs. unet WilcoxonResult(statistic=25703.0, pvalue=1.2125923894853416e-35)\n",
      "basic-student vs. basic-teacher WilcoxonResult(statistic=21511.5, pvalue=2.6519592018887243e-42)\n",
      "robust-teacher vs. robust-teacher-robust-student WilcoxonResult(statistic=16823.5, pvalue=1.862807843113924e-49)\n",
      "robust-teacher vs. robust-student WilcoxonResult(statistic=21599.0, pvalue=1.0231436542808156e-41)\n",
      "robust-teacher vs. unet-noisy WilcoxonResult(statistic=36785.0, pvalue=4.469158296944356e-20)\n",
      "robust-teacher vs. unet WilcoxonResult(statistic=67755.5, pvalue=0.9455020510482709)\n",
      "robust-teacher vs. basic-teacher WilcoxonResult(statistic=67094.5, pvalue=0.737187702319862)\n",
      "robust-teacher-robust-student vs. robust-student WilcoxonResult(statistic=67707.0, pvalue=0.7020145136538595)\n",
      "robust-teacher-robust-student vs. unet-noisy WilcoxonResult(statistic=10137.0, pvalue=2.3775156964318114e-64)\n",
      "robust-teacher-robust-student vs. unet WilcoxonResult(statistic=22990.5, pvalue=8.366855034423215e-40)\n",
      "robust-teacher-robust-student vs. basic-teacher WilcoxonResult(statistic=22764.5, pvalue=9.60544628561827e-40)\n",
      "robust-student vs. unet-noisy WilcoxonResult(statistic=9815.0, pvalue=4.9065118247083246e-65)\n",
      "robust-student vs. unet WilcoxonResult(statistic=24967.0, pvalue=1.3785055161811336e-36)\n",
      "robust-student vs. basic-teacher WilcoxonResult(statistic=19535.0, pvalue=4.098955214890793e-45)\n",
      "unet-noisy vs. unet WilcoxonResult(statistic=39996.5, pvalue=6.762917981649067e-17)\n",
      "unet-noisy vs. basic-teacher WilcoxonResult(statistic=34027.0, pvalue=7.674729553222124e-24)\n",
      "unet vs. basic-teacher WilcoxonResult(statistic=63341.5, pvalue=0.13474208478158256)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = [\"dice\", \"hd\", \"sd\"]\n",
    "experiment_names = list(experiments_info.keys())\n",
    "experiment_pairs = [(a, b) for idx, a in enumerate(experiment_names) for b in experiment_names[idx+1:]]\n",
    "for metric in metrics:\n",
    "    print(metric)\n",
    "    data ={}\n",
    "    for experiment_name in experiment_names:\n",
    "        x = df.loc[df.experiment_name==experiment_name, metric].values\n",
    "        data[experiment_name] = x\n",
    "    \n",
    "    for pair in experiment_pairs:\n",
    "        x, y = data[pair[0]], data[pair[1]]\n",
    "        test_stat = stats.wilcoxon(x, y)\n",
    "        print(f\"{pair[0]} vs. {pair[1]}\", test_stat)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dice', experiment_name\n",
      "basic-student                    True\n",
      "robust-student                   True\n",
      "robust-teacher                   True\n",
      "robust-teacher-robust-student    True\n",
      "Name: dice, dtype: bool)\n"
     ]
    }
   ],
   "source": [
    "for grp in x.items():\n",
    "    print(grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fa0cc5916a655ca8a08afbb58fc79ed9f1157e73551cc6da3387c9e4788706a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

digraph {
	graph [size="180.9,180.9"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140375998933728 [label="
 (2, 2, 17, 128, 128)" fillcolor=darkolivegreen1]
	140374603185264 [label=ConvolutionBackward0]
	140374603185552 -> 140374603185264
	140374603185552 [label=ReluBackward0]
	140374603182864 -> 140374603185552
	140374603182864 [label=NativeBatchNormBackward0]
	140374603184496 -> 140374603182864
	140374603184496 [label=AddBackward0]
	140374603185360 -> 140374603184496
	140374603185360 [label=ConvolutionBackward0]
	140374602502352 -> 140374603185360
	140374602502352 [label=ReluBackward0]
	140374602502256 -> 140374602502352
	140374602502256 [label=NativeBatchNormBackward0]
	140374602505424 -> 140374602502256
	140374602505424 [label=ConvolutionBackward0]
	140374602504224 -> 140374602505424
	140374602504224 [label=ReluBackward0]
	140374602503744 -> 140374602504224
	140374602503744 [label=NativeBatchNormBackward0]
	140374603185840 -> 140374602503744
	140374603185840 [label=AddBackward0]
	140374602503984 -> 140374603185840
	140374602503984 [label=ConvolutionBackward0]
	140374602504752 -> 140374602503984
	140374602504752 [label=ReluBackward0]
	140374602502304 -> 140374602504752
	140374602502304 [label=NativeBatchNormBackward0]
	140374602505472 -> 140374602502304
	140374602505472 [label=ConvolutionBackward0]
	140374602505856 -> 140374602505472
	140374602505856 [label=ReluBackward0]
	140374602502592 -> 140374602505856
	140374602502592 [label=NativeBatchNormBackward0]
	140374602503840 -> 140374602502592
	140374602503840 [label=AddBackward0]
	140374644167776 -> 140374602503840
	140374644167776 [label=ConvolutionBackward0]
	140374639755024 -> 140374644167776
	140374639755024 [label=ReluBackward0]
	140374603238464 -> 140374639755024
	140374603238464 [label=NativeBatchNormBackward0]
	140374603318656 -> 140374603238464
	140374603318656 [label=ConvolutionBackward0]
	140374639459728 -> 140374603318656
	140374639459728 [label=ReluBackward0]
	140375998873312 -> 140374639459728
	140375998873312 [label=NativeBatchNormBackward0]
	140375998871248 -> 140375998873312
	140375998871248 [label=CatBackward0]
	140375998872928 -> 140375998871248
	140375998872928 [label=AddBackward0]
	140375998871872 -> 140375998872928
	140375998871872 [label=ConvolutionBackward0]
	140375998871392 -> 140375998871872
	140375998871392 [label=ReluBackward0]
	140375998872736 -> 140375998871392
	140375998872736 [label=NativeBatchNormBackward0]
	140375998872784 -> 140375998872736
	140375998872784 [label=ConvolutionBackward0]
	140375998871008 -> 140375998872784
	140375998871008 [label=ReluBackward0]
	140375998873168 -> 140375998871008
	140375998873168 [label=NativeBatchNormBackward0]
	140375998872064 -> 140375998873168
	140375998872064 [label=AddBackward0]
	140375998739216 -> 140375998872064
	140375998739216 [label=ConvolutionBackward0]
	140375998738880 -> 140375998739216
	140375998738880 [label=ReluBackward0]
	140375998738784 -> 140375998738880
	140375998738784 [label=NativeBatchNormBackward0]
	140375998738592 -> 140375998738784
	140375998738592 [label=ConvolutionBackward0]
	140375998740032 -> 140375998738592
	140375998740032 [label=ReluBackward0]
	140375998741472 -> 140375998740032
	140375998741472 [label=NativeBatchNormBackward0]
	140375998739456 -> 140375998741472
	140375998739456 [label=AddBackward0]
	140375998739936 -> 140375998739456
	140375998739936 [label=ConvolutionBackward0]
	140375998741328 -> 140375998739936
	140375998741328 [label=ReluBackward0]
	140375998738976 -> 140375998741328
	140375998738976 [label=NativeBatchNormBackward0]
	140375998742384 -> 140375998738976
	140375998742384 [label=ConvolutionBackward0]
	140375998740560 -> 140375998742384
	140375998740560 [label=ReluBackward0]
	140375998955136 -> 140375998740560
	140375998955136 [label=NativeBatchNormBackward0]
	140375998955040 -> 140375998955136
	140374603180048 [label="downblocks.0.0.bn1.weight
 (1)" fillcolor=lightblue]
	140374603180048 -> 140375998955040
	140375998955040 [label=AccumulateGrad]
	140375998955088 -> 140375998955136
	140374603181088 [label="downblocks.0.0.bn1.bias
 (1)" fillcolor=lightblue]
	140374603181088 -> 140375998955088
	140375998955088 [label=AccumulateGrad]
	140375998955376 -> 140375998742384
	140375998728448 [label="downblocks.0.0.conv1.weight
 (64, 1, 3, 3, 3)" fillcolor=lightblue]
	140375998728448 -> 140375998955376
	140375998955376 [label=AccumulateGrad]
	140375998741520 -> 140375998738976
	140374603443472 [label="downblocks.0.0.bn2.weight
 (64)" fillcolor=lightblue]
	140374603443472 -> 140375998741520
	140375998741520 [label=AccumulateGrad]
	140375998740176 -> 140375998738976
	140375998728368 [label="downblocks.0.0.bn2.bias
 (64)" fillcolor=lightblue]
	140375998728368 -> 140375998740176
	140375998740176 [label=AccumulateGrad]
	140375998739888 -> 140375998739936
	140374603181408 [label="downblocks.0.0.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140374603181408 -> 140375998739888
	140375998739888 [label=AccumulateGrad]
	140375998738544 -> 140375998739456
	140375998738544 [label=ConvolutionBackward0]
	140375998740320 -> 140375998738544
	140374603180608 [label="downblocks.0.0.downsample.weight
 (64, 1, 1, 1, 1)" fillcolor=lightblue]
	140374603180608 -> 140375998740320
	140375998740320 [label=AccumulateGrad]
	140375998739168 -> 140375998741472
	140374633680624 [label="downblocks.0.1.bn1.weight
 (64)" fillcolor=lightblue]
	140374633680624 -> 140375998739168
	140375998739168 [label=AccumulateGrad]
	140375998740512 -> 140375998741472
	140375998847152 [label="downblocks.0.1.bn1.bias
 (64)" fillcolor=lightblue]
	140375998847152 -> 140375998740512
	140375998740512 [label=AccumulateGrad]
	140375998741664 -> 140375998738592
	140375998845712 [label="downblocks.0.1.conv1.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998845712 -> 140375998741664
	140375998741664 [label=AccumulateGrad]
	140375998738688 -> 140375998738784
	140375998845552 [label="downblocks.0.1.bn2.weight
 (64)" fillcolor=lightblue]
	140375998845552 -> 140375998738688
	140375998738688 [label=AccumulateGrad]
	140375998738832 -> 140375998738784
	140375998846912 [label="downblocks.0.1.bn2.bias
 (64)" fillcolor=lightblue]
	140375998846912 -> 140375998738832
	140375998738832 [label=AccumulateGrad]
	140375998739264 -> 140375998739216
	140374603321408 [label="downblocks.0.1.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140374603321408 -> 140375998739264
	140375998739264 [label=AccumulateGrad]
	140375998739456 -> 140375998872064
	140375998873120 -> 140375998873168
	140374603324928 [label="downblocks.0.2.bn1.weight
 (64)" fillcolor=lightblue]
	140374603324928 -> 140375998873120
	140375998873120 [label=AccumulateGrad]
	140375998873360 -> 140375998873168
	140374603323808 [label="downblocks.0.2.bn1.bias
 (64)" fillcolor=lightblue]
	140374603323808 -> 140375998873360
	140375998873360 [label=AccumulateGrad]
	140375998873456 -> 140375998872784
	140374603197952 [label="downblocks.0.2.conv1.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140374603197952 -> 140375998873456
	140375998873456 [label=AccumulateGrad]
	140375998869856 -> 140375998872736
	140374633249344 [label="downblocks.0.2.bn2.weight
 (64)" fillcolor=lightblue]
	140374633249344 -> 140375998869856
	140375998869856 [label=AccumulateGrad]
	140375998873072 -> 140375998872736
	140374603196592 [label="downblocks.0.2.bn2.bias
 (64)" fillcolor=lightblue]
	140374603196592 -> 140375998873072
	140375998873072 [label=AccumulateGrad]
	140375998872208 -> 140375998871872
	140374603195552 [label="downblocks.0.2.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140374603195552 -> 140375998872208
	140375998872208 [label=AccumulateGrad]
	140375998872064 -> 140375998872928
	140375998872160 -> 140375998871248
	140375998872160 [label=UpsampleTrilinear3DBackward1]
	140375998869568 -> 140375998872160
	140375998869568 [label=AddBackward0]
	140375998869952 -> 140375998869568
	140375998869952 [label=ConvolutionBackward0]
	140375998872976 -> 140375998869952
	140375998872976 [label=ReluBackward0]
	140375998742432 -> 140375998872976
	140375998742432 [label=NativeBatchNormBackward0]
	140375998741184 -> 140375998742432
	140375998741184 [label=ConvolutionBackward0]
	140375998738496 -> 140375998741184
	140375998738496 [label=ReluBackward0]
	140375998955328 -> 140375998738496
	140375998955328 [label=NativeBatchNormBackward0]
	140375998873024 -> 140375998955328
	140375998873024 [label=AddBackward0]
	140375998954656 -> 140375998873024
	140375998954656 [label=ConvolutionBackward0]
	140375998954512 -> 140375998954656
	140375998954512 [label=ReluBackward0]
	140375998954320 -> 140375998954512
	140375998954320 [label=NativeBatchNormBackward0]
	140375998954176 -> 140375998954320
	140375998954176 [label=ConvolutionBackward0]
	140375998953936 -> 140375998954176
	140375998953936 [label=ReluBackward0]
	140375998953744 -> 140375998953936
	140375998953744 [label=NativeBatchNormBackward0]
	140375998954800 -> 140375998953744
	140375998954800 [label=AddBackward0]
	140375998953264 -> 140375998954800
	140375998953264 [label=ConvolutionBackward0]
	140375998953072 -> 140375998953264
	140375998953072 [label=ReluBackward0]
	140375998952832 -> 140375998953072
	140375998952832 [label=NativeBatchNormBackward0]
	140375998952736 -> 140375998952832
	140375998952736 [label=ConvolutionBackward0]
	140375998952544 -> 140375998952736
	140375998952544 [label=ReluBackward0]
	140375998952400 -> 140375998952544
	140375998952400 [label=NativeBatchNormBackward0]
	140375998953360 -> 140375998952400
	140375998953360 [label=AddBackward0]
	140375998952160 -> 140375998953360
	140375998952160 [label=ConvolutionBackward0]
	140375998951920 -> 140375998952160
	140375998951920 [label=ReluBackward0]
	140375998951776 -> 140375998951920
	140375998951776 [label=NativeBatchNormBackward0]
	140375998951680 -> 140375998951776
	140375998951680 [label=ConvolutionBackward0]
	140375998954752 -> 140375998951680
	140375998954752 [label=ReluBackward0]
	140375998954704 -> 140375998954752
	140375998954704 [label=NativeBatchNormBackward0]
	140375998953120 -> 140375998954704
	140375998953120 [label=CatBackward0]
	140375998954944 -> 140375998953120
	140375998954944 [label=AddBackward0]
	140375998954272 -> 140375998954944
	140375998954272 [label=ConvolutionBackward0]
	140375998955280 -> 140375998954272
	140375998955280 [label=ReluBackward0]
	140375998509264 -> 140375998955280
	140375998509264 [label=NativeBatchNormBackward0]
	140375998509360 -> 140375998509264
	140375998509360 [label=ConvolutionBackward0]
	140375998509552 -> 140375998509360
	140375998509552 [label=ReluBackward0]
	140375998509696 -> 140375998509552
	140375998509696 [label=NativeBatchNormBackward0]
	140375998953456 -> 140375998509696
	140375998953456 [label=AddBackward0]
	140375998509936 -> 140375998953456
	140375998509936 [label=ConvolutionBackward0]
	140375998510080 -> 140375998509936
	140375998510080 [label=ReluBackward0]
	140375998510224 -> 140375998510080
	140375998510224 [label=NativeBatchNormBackward0]
	140375998510320 -> 140375998510224
	140375998510320 [label=ConvolutionBackward0]
	140375998510512 -> 140375998510320
	140375998510512 [label=ReluBackward0]
	140375998510656 -> 140375998510512
	140375998510656 [label=NativeBatchNormBackward0]
	140375998509888 -> 140375998510656
	140375998509888 [label=AddBackward0]
	140375998510896 -> 140375998509888
	140375998510896 [label=ConvolutionBackward0]
	140375998511040 -> 140375998510896
	140375998511040 [label=ReluBackward0]
	140375998511184 -> 140375998511040
	140375998511184 [label=NativeBatchNormBackward0]
	140375998511280 -> 140375998511184
	140375998511280 [label=ConvolutionBackward0]
	140375998511472 -> 140375998511280
	140375998511472 [label=ReluBackward0]
	140375998511616 -> 140375998511472
	140375998511616 [label=NativeBatchNormBackward0]
	140375998510848 -> 140375998511616
	140375998510848 [label=AddBackward0]
	140375998511856 -> 140375998510848
	140375998511856 [label=ConvolutionBackward0]
	140375998512000 -> 140375998511856
	140375998512000 [label=ReluBackward0]
	140375998512144 -> 140375998512000
	140375998512144 [label=NativeBatchNormBackward0]
	140375998512240 -> 140375998512144
	140375998512240 [label=ConvolutionBackward0]
	140375998512432 -> 140375998512240
	140375998512432 [label=ReluBackward0]
	140375998512576 -> 140375998512432
	140375998512576 [label=NativeBatchNormBackward0]
	140375998872928 -> 140375998512576
	140375998512672 -> 140375998512576
	140374603195712 [label="downblocks.1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140374603195712 -> 140375998512672
	140375998512672 [label=AccumulateGrad]
	140375998512624 -> 140375998512576
	140374603194672 [label="downblocks.1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140374603194672 -> 140375998512624
	140375998512624 [label=AccumulateGrad]
	140375998512384 -> 140375998512240
	140374603195952 [label="downblocks.1.0.conv1.weight
 (128, 64, 3, 3, 3)" fillcolor=lightblue]
	140374603195952 -> 140375998512384
	140375998512384 [label=AccumulateGrad]
	140375998512192 -> 140375998512144
	140374603195792 [label="downblocks.1.0.bn2.weight
 (128)" fillcolor=lightblue]
	140374603195792 -> 140375998512192
	140375998512192 [label=AccumulateGrad]
	140375998512048 -> 140375998512144
	140374603195472 [label="downblocks.1.0.bn2.bias
 (128)" fillcolor=lightblue]
	140374603195472 -> 140375998512048
	140375998512048 [label=AccumulateGrad]
	140375998511952 -> 140375998511856
	140374603196752 [label="downblocks.1.0.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140374603196752 -> 140375998511952
	140375998511952 [label=AccumulateGrad]
	140375998511808 -> 140375998510848
	140375998511808 [label=ConvolutionBackward0]
	140375998872928 -> 140375998511808
	140375998512288 -> 140375998511808
	140374603194832 [label="downblocks.1.0.downsample.weight
 (128, 64, 1, 1, 1)" fillcolor=lightblue]
	140374603194832 -> 140375998512288
	140375998512288 [label=AccumulateGrad]
	140375998511712 -> 140375998511616
	140374603196512 [label="downblocks.1.1.bn1.weight
 (128)" fillcolor=lightblue]
	140374603196512 -> 140375998511712
	140375998511712 [label=AccumulateGrad]
	140375998511664 -> 140375998511616
	140374603197632 [label="downblocks.1.1.bn1.bias
 (128)" fillcolor=lightblue]
	140374603197632 -> 140375998511664
	140375998511664 [label=AccumulateGrad]
	140375998511424 -> 140375998511280
	140374603196992 [label="downblocks.1.1.conv1.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140374603196992 -> 140375998511424
	140375998511424 [label=AccumulateGrad]
	140375998511232 -> 140375998511184
	140374603198272 [label="downblocks.1.1.bn2.weight
 (128)" fillcolor=lightblue]
	140374603198272 -> 140375998511232
	140375998511232 [label=AccumulateGrad]
	140375998511088 -> 140375998511184
	140374603198192 [label="downblocks.1.1.bn2.bias
 (128)" fillcolor=lightblue]
	140374603198192 -> 140375998511088
	140375998511088 [label=AccumulateGrad]
	140375998510992 -> 140375998510896
	140374604290224 [label="downblocks.1.1.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140374604290224 -> 140375998510992
	140375998510992 [label=AccumulateGrad]
	140375998510848 -> 140375998509888
	140375998510752 -> 140375998510656
	140375998728048 [label="downblocks.1.2.bn1.weight
 (128)" fillcolor=lightblue]
	140375998728048 -> 140375998510752
	140375998510752 [label=AccumulateGrad]
	140375998510704 -> 140375998510656
	140374624036640 [label="downblocks.1.2.bn1.bias
 (128)" fillcolor=lightblue]
	140374624036640 -> 140375998510704
	140375998510704 [label=AccumulateGrad]
	140375998510464 -> 140375998510320
	140374603178208 [label="downblocks.1.2.conv1.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140374603178208 -> 140375998510464
	140375998510464 [label=AccumulateGrad]
	140375998510272 -> 140375998510224
	140374603178288 [label="downblocks.1.2.bn2.weight
 (128)" fillcolor=lightblue]
	140374603178288 -> 140375998510272
	140375998510272 [label=AccumulateGrad]
	140375998510128 -> 140375998510224
	140374603178128 [label="downblocks.1.2.bn2.bias
 (128)" fillcolor=lightblue]
	140374603178128 -> 140375998510128
	140375998510128 [label=AccumulateGrad]
	140375998510032 -> 140375998509936
	140374603042704 [label="downblocks.1.2.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140374603042704 -> 140375998510032
	140375998510032 [label=AccumulateGrad]
	140375998509888 -> 140375998953456
	140375998509792 -> 140375998509696
	140374603040784 [label="downblocks.1.3.bn1.weight
 (128)" fillcolor=lightblue]
	140374603040784 -> 140375998509792
	140375998509792 [label=AccumulateGrad]
	140375998509744 -> 140375998509696
	140374603042544 [label="downblocks.1.3.bn1.bias
 (128)" fillcolor=lightblue]
	140374603042544 -> 140375998509744
	140375998509744 [label=AccumulateGrad]
	140375998509504 -> 140375998509360
	140374603040224 [label="downblocks.1.3.conv1.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140374603040224 -> 140375998509504
	140375998509504 [label=AccumulateGrad]
	140375998509312 -> 140375998509264
	140374603042624 [label="downblocks.1.3.bn2.weight
 (128)" fillcolor=lightblue]
	140374603042624 -> 140375998509312
	140375998509312 [label=AccumulateGrad]
	140375998509168 -> 140375998509264
	140374633679984 [label="downblocks.1.3.bn2.bias
 (128)" fillcolor=lightblue]
	140374633679984 -> 140375998509168
	140375998509168 [label=AccumulateGrad]
	140375998954224 -> 140375998954272
	140374644566192 [label="downblocks.1.3.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140374644566192 -> 140375998954224
	140375998954224 [label=AccumulateGrad]
	140375998953456 -> 140375998954944
	140375998955232 -> 140375998953120
	140375998955232 [label=UpsampleTrilinear3DBackward1]
	140375998951632 -> 140375998955232
	140375998951632 [label=AddBackward0]
	140375998509216 -> 140375998951632
	140375998509216 [label=ConvolutionBackward0]
	140375998509648 -> 140375998509216
	140375998509648 [label=ReluBackward0]
	140375998510368 -> 140375998509648
	140375998510368 [label=NativeBatchNormBackward0]
	140375998510800 -> 140375998510368
	140375998510800 [label=ConvolutionBackward0]
	140375998511376 -> 140375998510800
	140375998511376 [label=ReluBackward0]
	140375998511760 -> 140375998511376
	140375998511760 [label=NativeBatchNormBackward0]
	140375998509408 -> 140375998511760
	140375998509408 [label=AddBackward0]
	140375998512096 -> 140375998509408
	140375998512096 [label=ConvolutionBackward0]
	140375998512528 -> 140375998512096
	140375998512528 [label=ReluBackward0]
	140375998512864 -> 140375998512528
	140375998512864 [label=NativeBatchNormBackward0]
	140375998512960 -> 140375998512864
	140375998512960 [label=ConvolutionBackward0]
	140375998513104 -> 140375998512960
	140375998513104 [label=ReluBackward0]
	140375998529744 -> 140375998513104
	140375998529744 [label=NativeBatchNormBackward0]
	140375998512720 -> 140375998529744
	140375998512720 [label=AddBackward0]
	140375998529984 -> 140375998512720
	140375998529984 [label=ConvolutionBackward0]
	140375998530128 -> 140375998529984
	140375998530128 [label=ReluBackward0]
	140375998530272 -> 140375998530128
	140375998530272 [label=NativeBatchNormBackward0]
	140375998530368 -> 140375998530272
	140375998530368 [label=ConvolutionBackward0]
	140375998530560 -> 140375998530368
	140375998530560 [label=ReluBackward0]
	140375998530704 -> 140375998530560
	140375998530704 [label=NativeBatchNormBackward0]
	140375998529936 -> 140375998530704
	140375998529936 [label=AddBackward0]
	140375998530944 -> 140375998529936
	140375998530944 [label=ConvolutionBackward0]
	140375998531088 -> 140375998530944
	140375998531088 [label=ReluBackward0]
	140375998531232 -> 140375998531088
	140375998531232 [label=NativeBatchNormBackward0]
	140375998531328 -> 140375998531232
	140375998531328 [label=ConvolutionBackward0]
	140375998531520 -> 140375998531328
	140375998531520 [label=ReluBackward0]
	140375998531664 -> 140375998531520
	140375998531664 [label=NativeBatchNormBackward0]
	140375998530896 -> 140375998531664
	140375998530896 [label=AddBackward0]
	140375998531904 -> 140375998530896
	140375998531904 [label=ConvolutionBackward0]
	140375998532048 -> 140375998531904
	140375998532048 [label=ReluBackward0]
	140375998532192 -> 140375998532048
	140375998532192 [label=NativeBatchNormBackward0]
	140375998532288 -> 140375998532192
	140375998532288 [label=ConvolutionBackward0]
	140375998532480 -> 140375998532288
	140375998532480 [label=ReluBackward0]
	140375998532624 -> 140375998532480
	140375998532624 [label=NativeBatchNormBackward0]
	140375998531856 -> 140375998532624
	140375998531856 [label=AddBackward0]
	140375998532864 -> 140375998531856
	140375998532864 [label=ConvolutionBackward0]
	140375998533008 -> 140375998532864
	140375998533008 [label=ReluBackward0]
	140375998533152 -> 140375998533008
	140375998533152 [label=NativeBatchNormBackward0]
	140375998533248 -> 140375998533152
	140375998533248 [label=ConvolutionBackward0]
	140375998533440 -> 140375998533248
	140375998533440 [label=ReluBackward0]
	140375998533584 -> 140375998533440
	140375998533584 [label=NativeBatchNormBackward0]
	140375998533488 -> 140375998533584
	140375998533488 [label=CatBackward0]
	140375961026864 -> 140375998533488
	140375961026864 [label=AddBackward0]
	140375961027008 -> 140375961026864
	140375961027008 [label=ConvolutionBackward0]
	140375961027152 -> 140375961027008
	140375961027152 [label=ReluBackward0]
	140375961027296 -> 140375961027152
	140375961027296 [label=NativeBatchNormBackward0]
	140375961027392 -> 140375961027296
	140375961027392 [label=ConvolutionBackward0]
	140375961027584 -> 140375961027392
	140375961027584 [label=ReluBackward0]
	140375961027728 -> 140375961027584
	140375961027728 [label=NativeBatchNormBackward0]
	140375961026960 -> 140375961027728
	140375961026960 [label=AddBackward0]
	140375961027968 -> 140375961026960
	140375961027968 [label=ConvolutionBackward0]
	140375961028112 -> 140375961027968
	140375961028112 [label=ReluBackward0]
	140375961028256 -> 140375961028112
	140375961028256 [label=NativeBatchNormBackward0]
	140375961028352 -> 140375961028256
	140375961028352 [label=ConvolutionBackward0]
	140375961028544 -> 140375961028352
	140375961028544 [label=ReluBackward0]
	140375961028688 -> 140375961028544
	140375961028688 [label=NativeBatchNormBackward0]
	140375961027920 -> 140375961028688
	140375961027920 [label=AddBackward0]
	140375961028928 -> 140375961027920
	140375961028928 [label=ConvolutionBackward0]
	140375961029072 -> 140375961028928
	140375961029072 [label=ReluBackward0]
	140375961029216 -> 140375961029072
	140375961029216 [label=NativeBatchNormBackward0]
	140375961029312 -> 140375961029216
	140375961029312 [label=ConvolutionBackward0]
	140375961029504 -> 140375961029312
	140375961029504 [label=ReluBackward0]
	140375961029648 -> 140375961029504
	140375961029648 [label=NativeBatchNormBackward0]
	140375961028880 -> 140375961029648
	140375961028880 [label=AddBackward0]
	140375961029888 -> 140375961028880
	140375961029888 [label=ConvolutionBackward0]
	140375961030032 -> 140375961029888
	140375961030032 [label=ReluBackward0]
	140375961030176 -> 140375961030032
	140375961030176 [label=NativeBatchNormBackward0]
	140375961030272 -> 140375961030176
	140375961030272 [label=ConvolutionBackward0]
	140375961030464 -> 140375961030272
	140375961030464 [label=ReluBackward0]
	140375961030608 -> 140375961030464
	140375961030608 [label=NativeBatchNormBackward0]
	140375961029840 -> 140375961030608
	140375961029840 [label=AddBackward0]
	140375961018624 -> 140375961029840
	140375961018624 [label=ConvolutionBackward0]
	140375961018768 -> 140375961018624
	140375961018768 [label=ReluBackward0]
	140375961018912 -> 140375961018768
	140375961018912 [label=NativeBatchNormBackward0]
	140375961019008 -> 140375961018912
	140375961019008 [label=ConvolutionBackward0]
	140375961019200 -> 140375961019008
	140375961019200 [label=ReluBackward0]
	140375961019344 -> 140375961019200
	140375961019344 [label=NativeBatchNormBackward0]
	140375961018576 -> 140375961019344
	140375961018576 [label=AddBackward0]
	140375961019584 -> 140375961018576
	140375961019584 [label=ConvolutionBackward0]
	140375961019728 -> 140375961019584
	140375961019728 [label=ReluBackward0]
	140375961019872 -> 140375961019728
	140375961019872 [label=NativeBatchNormBackward0]
	140375961019968 -> 140375961019872
	140375961019968 [label=ConvolutionBackward0]
	140375961020160 -> 140375961019968
	140375961020160 [label=ReluBackward0]
	140375961020304 -> 140375961020160
	140375961020304 [label=NativeBatchNormBackward0]
	140375998954944 -> 140375961020304
	140375961020400 -> 140375961020304
	140374644564512 [label="downblocks.2.0.bn1.weight
 (128)" fillcolor=lightblue]
	140374644564512 -> 140375961020400
	140375961020400 [label=AccumulateGrad]
	140375961020352 -> 140375961020304
	140374619286880 [label="downblocks.2.0.bn1.bias
 (128)" fillcolor=lightblue]
	140374619286880 -> 140375961020352
	140375961020352 [label=AccumulateGrad]
	140375961020112 -> 140375961019968
	140374603032592 [label="downblocks.2.0.conv1.weight
 (256, 128, 3, 3, 3)" fillcolor=lightblue]
	140374603032592 -> 140375961020112
	140375961020112 [label=AccumulateGrad]
	140375961019920 -> 140375961019872
	140374603032512 [label="downblocks.2.0.bn2.weight
 (256)" fillcolor=lightblue]
	140374603032512 -> 140375961019920
	140375961019920 [label=AccumulateGrad]
	140375961019776 -> 140375961019872
	140374603032992 [label="downblocks.2.0.bn2.bias
 (256)" fillcolor=lightblue]
	140374603032992 -> 140375961019776
	140375961019776 [label=AccumulateGrad]
	140375961019680 -> 140375961019584
	140374603029456 [label="downblocks.2.0.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603029456 -> 140375961019680
	140375961019680 [label=AccumulateGrad]
	140375961019536 -> 140375961018576
	140375961019536 [label=ConvolutionBackward0]
	140375998954944 -> 140375961019536
	140375961020016 -> 140375961019536
	140374633679424 [label="downblocks.2.0.downsample.weight
 (256, 128, 1, 1, 1)" fillcolor=lightblue]
	140374633679424 -> 140375961020016
	140375961020016 [label=AccumulateGrad]
	140375961019440 -> 140375961019344
	140374603032112 [label="downblocks.2.1.bn1.weight
 (256)" fillcolor=lightblue]
	140374603032112 -> 140375961019440
	140375961019440 [label=AccumulateGrad]
	140375961019392 -> 140375961019344
	140374603028336 [label="downblocks.2.1.bn1.bias
 (256)" fillcolor=lightblue]
	140374603028336 -> 140375961019392
	140375961019392 [label=AccumulateGrad]
	140375961019152 -> 140375961019008
	140374603026496 [label="downblocks.2.1.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603026496 -> 140375961019152
	140375961019152 [label=AccumulateGrad]
	140375961018960 -> 140375961018912
	140374603028576 [label="downblocks.2.1.bn2.weight
 (256)" fillcolor=lightblue]
	140374603028576 -> 140375961018960
	140375961018960 [label=AccumulateGrad]
	140375961018816 -> 140375961018912
	140374603312080 [label="downblocks.2.1.bn2.bias
 (256)" fillcolor=lightblue]
	140374603312080 -> 140375961018816
	140375961018816 [label=AccumulateGrad]
	140375961018720 -> 140375961018624
	140374603277552 [label="downblocks.2.1.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603277552 -> 140375961018720
	140375961018720 [label=AccumulateGrad]
	140375961018576 -> 140375961029840
	140375961030512 -> 140375961030608
	140374603280112 [label="downblocks.2.2.bn1.weight
 (256)" fillcolor=lightblue]
	140374603280112 -> 140375961030512
	140375961030512 [label=AccumulateGrad]
	140375961018480 -> 140375961030608
	140374603443072 [label="downblocks.2.2.bn1.bias
 (256)" fillcolor=lightblue]
	140374603443072 -> 140375961018480
	140375961018480 [label=AccumulateGrad]
	140375961030416 -> 140375961030272
	140374603440512 [label="downblocks.2.2.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603440512 -> 140375961030416
	140375961030416 [label=AccumulateGrad]
	140375961030224 -> 140375961030176
	140374603440832 [label="downblocks.2.2.bn2.weight
 (256)" fillcolor=lightblue]
	140374603440832 -> 140375961030224
	140375961030224 [label=AccumulateGrad]
	140375961030080 -> 140375961030176
	140374603440432 [label="downblocks.2.2.bn2.bias
 (256)" fillcolor=lightblue]
	140374603440432 -> 140375961030080
	140375961030080 [label=AccumulateGrad]
	140375961029984 -> 140375961029888
	140374603440752 [label="downblocks.2.2.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603440752 -> 140375961029984
	140375961029984 [label=AccumulateGrad]
	140375961029840 -> 140375961028880
	140375961029744 -> 140375961029648
	140374603442672 [label="downblocks.2.3.bn1.weight
 (256)" fillcolor=lightblue]
	140374603442672 -> 140375961029744
	140375961029744 [label=AccumulateGrad]
	140375961029696 -> 140375961029648
	140374603442272 [label="downblocks.2.3.bn1.bias
 (256)" fillcolor=lightblue]
	140374603442272 -> 140375961029696
	140375961029696 [label=AccumulateGrad]
	140375961029456 -> 140375961029312
	140374603441872 [label="downblocks.2.3.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603441872 -> 140375961029456
	140375961029456 [label=AccumulateGrad]
	140375961029264 -> 140375961029216
	140374603442192 [label="downblocks.2.3.bn2.weight
 (256)" fillcolor=lightblue]
	140374603442192 -> 140375961029264
	140375961029264 [label=AccumulateGrad]
	140375961029120 -> 140375961029216
	140374604015792 [label="downblocks.2.3.bn2.bias
 (256)" fillcolor=lightblue]
	140374604015792 -> 140375961029120
	140375961029120 [label=AccumulateGrad]
	140375961029024 -> 140375961028928
	140374603012832 [label="downblocks.2.3.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603012832 -> 140375961029024
	140375961029024 [label=AccumulateGrad]
	140375961028880 -> 140375961027920
	140375961028784 -> 140375961028688
	140374603013152 [label="downblocks.2.4.bn1.weight
 (256)" fillcolor=lightblue]
	140374603013152 -> 140375961028784
	140375961028784 [label=AccumulateGrad]
	140375961028736 -> 140375961028688
	140374603011792 [label="downblocks.2.4.bn1.bias
 (256)" fillcolor=lightblue]
	140374603011792 -> 140375961028736
	140375961028736 [label=AccumulateGrad]
	140375961028496 -> 140375961028352
	140374603013552 [label="downblocks.2.4.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603013552 -> 140375961028496
	140375961028496 [label=AccumulateGrad]
	140375961028304 -> 140375961028256
	140374603012432 [label="downblocks.2.4.bn2.weight
 (256)" fillcolor=lightblue]
	140374603012432 -> 140375961028304
	140375961028304 [label=AccumulateGrad]
	140375961028160 -> 140375961028256
	140374603440016 [label="downblocks.2.4.bn2.bias
 (256)" fillcolor=lightblue]
	140374603440016 -> 140375961028160
	140375961028160 [label=AccumulateGrad]
	140375961028064 -> 140375961027968
	140374603745856 [label="downblocks.2.4.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603745856 -> 140375961028064
	140375961028064 [label=AccumulateGrad]
	140375961027920 -> 140375961026960
	140375961027824 -> 140375961027728
	140374603745216 [label="downblocks.2.5.bn1.weight
 (256)" fillcolor=lightblue]
	140374603745216 -> 140375961027824
	140375961027824 [label=AccumulateGrad]
	140375961027776 -> 140375961027728
	140374603744736 [label="downblocks.2.5.bn1.bias
 (256)" fillcolor=lightblue]
	140374603744736 -> 140375961027776
	140375961027776 [label=AccumulateGrad]
	140375961027536 -> 140375961027392
	140374645303552 [label="downblocks.2.5.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374645303552 -> 140375961027536
	140375961027536 [label=AccumulateGrad]
	140375961027344 -> 140375961027296
	140374603733648 [label="downblocks.2.5.bn2.weight
 (256)" fillcolor=lightblue]
	140374603733648 -> 140375961027344
	140375961027344 [label=AccumulateGrad]
	140375961027200 -> 140375961027296
	140374602483808 [label="downblocks.2.5.bn2.bias
 (256)" fillcolor=lightblue]
	140374602483808 -> 140375961027200
	140375961027200 [label=AccumulateGrad]
	140375961027104 -> 140375961027008
	140374602483008 [label="downblocks.2.5.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140374602483008 -> 140375961027104
	140375961027104 [label=AccumulateGrad]
	140375961026960 -> 140375961026864
	140375961026816 -> 140375998533488
	140375961026816 [label=UpsampleTrilinear3DBackward1]
	140375961027488 -> 140375961026816
	140375961027488 [label=AddBackward0]
	140375961027248 -> 140375961027488
	140375961027248 [label=ConvolutionBackward0]
	140375961027680 -> 140375961027248
	140375961027680 [label=ReluBackward0]
	140375961028400 -> 140375961027680
	140375961028400 [label=NativeBatchNormBackward0]
	140375961028832 -> 140375961028400
	140375961028832 [label=ConvolutionBackward0]
	140375961029408 -> 140375961028832
	140375961029408 [label=ReluBackward0]
	140375961029792 -> 140375961029408
	140375961029792 [label=NativeBatchNormBackward0]
	140375961027440 -> 140375961029792
	140375961027440 [label=AddBackward0]
	140375961030320 -> 140375961027440
	140375961030320 [label=ConvolutionBackward0]
	140375961030560 -> 140375961030320
	140375961030560 [label=ReluBackward0]
	140375961019104 -> 140375961030560
	140375961019104 [label=NativeBatchNormBackward0]
	140375961018864 -> 140375961019104
	140375961018864 [label=ConvolutionBackward0]
	140375961020064 -> 140375961018864
	140375961020064 [label=ReluBackward0]
	140375961019632 -> 140375961020064
	140375961019632 [label=NativeBatchNormBackward0]
	140375961030368 -> 140375961019632
	140375961030368 [label=AddBackward0]
	140375961020592 -> 140375961030368
	140375961020592 [label=ConvolutionBackward0]
	140375961020736 -> 140375961020592
	140375961020736 [label=ReluBackward0]
	140375961020880 -> 140375961020736
	140375961020880 [label=NativeBatchNormBackward0]
	140375961020976 -> 140375961020880
	140375961020976 [label=ConvolutionBackward0]
	140375961021168 -> 140375961020976
	140375961021168 [label=ReluBackward0]
	140375961021312 -> 140375961021168
	140375961021312 [label=NativeBatchNormBackward0]
	140375961026864 -> 140375961021312
	140375961021408 -> 140375961021312
	140374602482528 [label="downblocks.3.0.bn1.weight
 (256)" fillcolor=lightblue]
	140374602482528 -> 140375961021408
	140375961021408 [label=AccumulateGrad]
	140375961021360 -> 140375961021312
	140374602482048 [label="downblocks.3.0.bn1.bias
 (256)" fillcolor=lightblue]
	140374602482048 -> 140375961021360
	140375961021360 [label=AccumulateGrad]
	140375961021120 -> 140375961020976
	140374602572560 [label="downblocks.3.0.conv1.weight
 (512, 256, 3, 3, 3)" fillcolor=lightblue]
	140374602572560 -> 140375961021120
	140375961021120 [label=AccumulateGrad]
	140375961020928 -> 140375961020880
	140374602483968 [label="downblocks.3.0.bn2.weight
 (512)" fillcolor=lightblue]
	140374602483968 -> 140375961020928
	140375961020928 [label=AccumulateGrad]
	140375961020784 -> 140375961020880
	140374602572480 [label="downblocks.3.0.bn2.bias
 (512)" fillcolor=lightblue]
	140374602572480 -> 140375961020784
	140375961020784 [label=AccumulateGrad]
	140375961020688 -> 140375961020592
	140374602574960 [label="downblocks.3.0.conv2.weight
 (512, 512, 3, 3, 3)" fillcolor=lightblue]
	140374602574960 -> 140375961020688
	140375961020688 [label=AccumulateGrad]
	140375961020544 -> 140375961030368
	140375961020544 [label=ConvolutionBackward0]
	140375961026864 -> 140375961020544
	140375961021024 -> 140375961020544
	140374602483488 [label="downblocks.3.0.downsample.weight
 (512, 256, 1, 1, 1)" fillcolor=lightblue]
	140374602483488 -> 140375961021024
	140375961021024 [label=AccumulateGrad]
	140375961020256 -> 140375961019632
	140374602574480 [label="downblocks.3.1.bn1.weight
 (512)" fillcolor=lightblue]
	140374602574480 -> 140375961020256
	140375961020256 [label=AccumulateGrad]
	140375961020208 -> 140375961019632
	140374602575520 [label="downblocks.3.1.bn1.bias
 (512)" fillcolor=lightblue]
	140374602575520 -> 140375961020208
	140375961020208 [label=AccumulateGrad]
	140375961019296 -> 140375961018864
	140374602575200 [label="downblocks.3.1.conv1.weight
 (512, 512, 3, 3, 3)" fillcolor=lightblue]
	140374602575200 -> 140375961019296
	140375961019296 [label=AccumulateGrad]
	140375961019056 -> 140375961019104
	140374602574240 [label="downblocks.3.1.bn2.weight
 (512)" fillcolor=lightblue]
	140374602574240 -> 140375961019056
	140375961019056 [label=AccumulateGrad]
	140375961018432 -> 140375961019104
	140374602575760 [label="downblocks.3.1.bn2.bias
 (512)" fillcolor=lightblue]
	140374602575760 -> 140375961018432
	140375961018432 [label=AccumulateGrad]
	140375961030128 -> 140375961030320
	140374633603296 [label="downblocks.3.1.conv2.weight
 (512, 512, 3, 3, 3)" fillcolor=lightblue]
	140374633603296 -> 140375961030128
	140375961030128 [label=AccumulateGrad]
	140375961030368 -> 140375961027440
	140375961029600 -> 140375961029792
	140374633603776 [label="downblocks.3.2.bn1.weight
 (512)" fillcolor=lightblue]
	140374633603776 -> 140375961029600
	140375961029600 [label=AccumulateGrad]
	140375961029552 -> 140375961029792
	140374603221328 [label="downblocks.3.2.bn1.bias
 (512)" fillcolor=lightblue]
	140374603221328 -> 140375961029552
	140375961029552 [label=AccumulateGrad]
	140375961028976 -> 140375961028832
	140374603219408 [label="downblocks.3.2.conv1.weight
 (512, 512, 3, 3, 3)" fillcolor=lightblue]
	140374603219408 -> 140375961028976
	140375961028976 [label=AccumulateGrad]
	140375961028208 -> 140375961028400
	140374603222848 [label="downblocks.3.2.bn2.weight
 (512)" fillcolor=lightblue]
	140374603222848 -> 140375961028208
	140375961028208 [label=AccumulateGrad]
	140375961028016 -> 140375961028400
	140374603219168 [label="downblocks.3.2.bn2.bias
 (512)" fillcolor=lightblue]
	140374603219168 -> 140375961028016
	140375961028016 [label=AccumulateGrad]
	140375961027632 -> 140375961027248
	140374603222688 [label="downblocks.3.2.conv2.weight
 (512, 512, 3, 3, 3)" fillcolor=lightblue]
	140374603222688 -> 140375961027632
	140375961027632 [label=AccumulateGrad]
	140375961027440 -> 140375961027488
	140375961026672 -> 140375998533584
	140374603220368 [label="upblocks.0.0.bn1.weight
 (768)" fillcolor=lightblue]
	140374603220368 -> 140375961026672
	140375961026672 [label=AccumulateGrad]
	140375961026624 -> 140375998533584
	140374603222608 [label="upblocks.0.0.bn1.bias
 (768)" fillcolor=lightblue]
	140374603222608 -> 140375961026624
	140375961026624 [label=AccumulateGrad]
	140375998533392 -> 140375998533248
	140374603222448 [label="upblocks.0.0.conv1.weight
 (256, 768, 3, 3, 3)" fillcolor=lightblue]
	140374603222448 -> 140375998533392
	140375998533392 [label=AccumulateGrad]
	140375998533200 -> 140375998533152
	140374603220528 [label="upblocks.0.0.bn2.weight
 (256)" fillcolor=lightblue]
	140374603220528 -> 140375998533200
	140375998533200 [label=AccumulateGrad]
	140375998533056 -> 140375998533152
	140374603222368 [label="upblocks.0.0.bn2.bias
 (256)" fillcolor=lightblue]
	140374603222368 -> 140375998533056
	140375998533056 [label=AccumulateGrad]
	140375998532960 -> 140375998532864
	140375960938032 [label="upblocks.0.0.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375960938032 -> 140375998532960
	140375998532960 [label=AccumulateGrad]
	140375998532816 -> 140375998531856
	140375998532816 [label=ConvolutionBackward0]
	140375998533488 -> 140375998532816
	140375998533296 -> 140375998532816
	140374603219328 [label="upblocks.0.0.downsample.weight
 (256, 768, 1, 1, 1)" fillcolor=lightblue]
	140374603219328 -> 140375998533296
	140375998533296 [label=AccumulateGrad]
	140375998532720 -> 140375998532624
	140375960937952 [label="upblocks.0.1.bn1.weight
 (256)" fillcolor=lightblue]
	140375960937952 -> 140375998532720
	140375998532720 [label=AccumulateGrad]
	140375998532672 -> 140375998532624
	140375960938112 [label="upblocks.0.1.bn1.bias
 (256)" fillcolor=lightblue]
	140375960938112 -> 140375998532672
	140375998532672 [label=AccumulateGrad]
	140375998532432 -> 140375998532288
	140375960938512 [label="upblocks.0.1.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375960938512 -> 140375998532432
	140375998532432 [label=AccumulateGrad]
	140375998532240 -> 140375998532192
	140375960938432 [label="upblocks.0.1.bn2.weight
 (256)" fillcolor=lightblue]
	140375960938432 -> 140375998532240
	140375998532240 [label=AccumulateGrad]
	140375998532096 -> 140375998532192
	140375960938592 [label="upblocks.0.1.bn2.bias
 (256)" fillcolor=lightblue]
	140375960938592 -> 140375998532096
	140375998532096 [label=AccumulateGrad]
	140375998532000 -> 140375998531904
	140375960938992 [label="upblocks.0.1.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375960938992 -> 140375998532000
	140375998532000 [label=AccumulateGrad]
	140375998531856 -> 140375998530896
	140375998531760 -> 140375998531664
	140375960938912 [label="upblocks.0.2.bn1.weight
 (256)" fillcolor=lightblue]
	140375960938912 -> 140375998531760
	140375998531760 [label=AccumulateGrad]
	140375998531712 -> 140375998531664
	140375960939072 [label="upblocks.0.2.bn1.bias
 (256)" fillcolor=lightblue]
	140375960939072 -> 140375998531712
	140375998531712 [label=AccumulateGrad]
	140375998531472 -> 140375998531328
	140375960939472 [label="upblocks.0.2.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375960939472 -> 140375998531472
	140375998531472 [label=AccumulateGrad]
	140375998531280 -> 140375998531232
	140375960939392 [label="upblocks.0.2.bn2.weight
 (256)" fillcolor=lightblue]
	140375960939392 -> 140375998531280
	140375998531280 [label=AccumulateGrad]
	140375998531136 -> 140375998531232
	140375960939552 [label="upblocks.0.2.bn2.bias
 (256)" fillcolor=lightblue]
	140375960939552 -> 140375998531136
	140375998531136 [label=AccumulateGrad]
	140375998531040 -> 140375998530944
	140375960939952 [label="upblocks.0.2.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375960939952 -> 140375998531040
	140375998531040 [label=AccumulateGrad]
	140375998530896 -> 140375998529936
	140375998530800 -> 140375998530704
	140375960939872 [label="upblocks.0.3.bn1.weight
 (256)" fillcolor=lightblue]
	140375960939872 -> 140375998530800
	140375998530800 [label=AccumulateGrad]
	140375998530752 -> 140375998530704
	140375960940032 [label="upblocks.0.3.bn1.bias
 (256)" fillcolor=lightblue]
	140375960940032 -> 140375998530752
	140375998530752 [label=AccumulateGrad]
	140375998530512 -> 140375998530368
	140375960940432 [label="upblocks.0.3.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375960940432 -> 140375998530512
	140375998530512 [label=AccumulateGrad]
	140375998530320 -> 140375998530272
	140375960940352 [label="upblocks.0.3.bn2.weight
 (256)" fillcolor=lightblue]
	140375960940352 -> 140375998530320
	140375998530320 [label=AccumulateGrad]
	140375998530176 -> 140375998530272
	140375998300224 [label="upblocks.0.3.bn2.bias
 (256)" fillcolor=lightblue]
	140375998300224 -> 140375998530176
	140375998530176 [label=AccumulateGrad]
	140375998530080 -> 140375998529984
	140375998300624 [label="upblocks.0.3.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375998300624 -> 140375998530080
	140375998530080 [label=AccumulateGrad]
	140375998529936 -> 140375998512720
	140375998529840 -> 140375998529744
	140375998300544 [label="upblocks.0.4.bn1.weight
 (256)" fillcolor=lightblue]
	140375998300544 -> 140375998529840
	140375998529840 [label=AccumulateGrad]
	140375998529792 -> 140375998529744
	140375998300704 [label="upblocks.0.4.bn1.bias
 (256)" fillcolor=lightblue]
	140375998300704 -> 140375998529792
	140375998529792 [label=AccumulateGrad]
	140375998513056 -> 140375998512960
	140375998301104 [label="upblocks.0.4.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375998301104 -> 140375998513056
	140375998513056 [label=AccumulateGrad]
	140375998512912 -> 140375998512864
	140375998301024 [label="upblocks.0.4.bn2.weight
 (256)" fillcolor=lightblue]
	140375998301024 -> 140375998512912
	140375998512912 [label=AccumulateGrad]
	140375998512768 -> 140375998512864
	140375998301184 [label="upblocks.0.4.bn2.bias
 (256)" fillcolor=lightblue]
	140375998301184 -> 140375998512768
	140375998512768 [label=AccumulateGrad]
	140375998512480 -> 140375998512096
	140375998301584 [label="upblocks.0.4.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375998301584 -> 140375998512480
	140375998512480 [label=AccumulateGrad]
	140375998512720 -> 140375998509408
	140375998511568 -> 140375998511760
	140375998301504 [label="upblocks.0.5.bn1.weight
 (256)" fillcolor=lightblue]
	140375998301504 -> 140375998511568
	140375998511568 [label=AccumulateGrad]
	140375998511520 -> 140375998511760
	140375998301664 [label="upblocks.0.5.bn1.bias
 (256)" fillcolor=lightblue]
	140375998301664 -> 140375998511520
	140375998511520 [label=AccumulateGrad]
	140375998510944 -> 140375998510800
	140375998302064 [label="upblocks.0.5.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375998302064 -> 140375998510944
	140375998510944 [label=AccumulateGrad]
	140375998510176 -> 140375998510368
	140375998301984 [label="upblocks.0.5.bn2.weight
 (256)" fillcolor=lightblue]
	140375998301984 -> 140375998510176
	140375998510176 [label=AccumulateGrad]
	140375998509984 -> 140375998510368
	140375998302144 [label="upblocks.0.5.bn2.bias
 (256)" fillcolor=lightblue]
	140375998302144 -> 140375998509984
	140375998509984 [label=AccumulateGrad]
	140375998509600 -> 140375998509216
	140375998302544 [label="upblocks.0.5.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375998302544 -> 140375998509600
	140375998509600 [label=AccumulateGrad]
	140375998509408 -> 140375998951632
	140375998953312 -> 140375998954704
	140375998302624 [label="upblocks.1.0.bn1.weight
 (384)" fillcolor=lightblue]
	140375998302624 -> 140375998953312
	140375998953312 [label=AccumulateGrad]
	140375998955472 -> 140375998954704
	140375998302704 [label="upblocks.1.0.bn1.bias
 (384)" fillcolor=lightblue]
	140375998302704 -> 140375998955472
	140375998955472 [label=AccumulateGrad]
	140375998951488 -> 140375998951680
	140375998303104 [label="upblocks.1.0.conv1.weight
 (128, 384, 3, 3, 3)" fillcolor=lightblue]
	140375998303104 -> 140375998951488
	140375998951488 [label=AccumulateGrad]
	140375998951728 -> 140375998951776
	140375998303024 [label="upblocks.1.0.bn2.weight
 (128)" fillcolor=lightblue]
	140375998303024 -> 140375998951728
	140375998951728 [label=AccumulateGrad]
	140375998951968 -> 140375998951776
	140375998303184 [label="upblocks.1.0.bn2.bias
 (128)" fillcolor=lightblue]
	140375998303184 -> 140375998951968
	140375998951968 [label=AccumulateGrad]
	140375998952016 -> 140375998952160
	140375998303584 [label="upblocks.1.0.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998303584 -> 140375998952016
	140375998952016 [label=AccumulateGrad]
	140375998952208 -> 140375998953360
	140375998952208 [label=ConvolutionBackward0]
	140375998953120 -> 140375998952208
	140375998951584 -> 140375998952208
	140375998302464 [label="upblocks.1.0.downsample.weight
 (128, 384, 1, 1, 1)" fillcolor=lightblue]
	140375998302464 -> 140375998951584
	140375998951584 [label=AccumulateGrad]
	140375998952304 -> 140375998952400
	140375998303504 [label="upblocks.1.1.bn1.weight
 (128)" fillcolor=lightblue]
	140375998303504 -> 140375998952304
	140375998952304 [label=AccumulateGrad]
	140375998952352 -> 140375998952400
	140375998303664 [label="upblocks.1.1.bn1.bias
 (128)" fillcolor=lightblue]
	140375998303664 -> 140375998952352
	140375998952352 [label=AccumulateGrad]
	140375998952592 -> 140375998952736
	140375998304064 [label="upblocks.1.1.conv1.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998304064 -> 140375998952592
	140375998952592 [label=AccumulateGrad]
	140375998952784 -> 140375998952832
	140375998303984 [label="upblocks.1.1.bn2.weight
 (128)" fillcolor=lightblue]
	140375998303984 -> 140375998952784
	140375998952784 [label=AccumulateGrad]
	140375998952976 -> 140375998952832
	140375998304144 [label="upblocks.1.1.bn2.bias
 (128)" fillcolor=lightblue]
	140375998304144 -> 140375998952976
	140375998952976 [label=AccumulateGrad]
	140375998953168 -> 140375998953264
	140375998386560 [label="upblocks.1.1.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998386560 -> 140375998953168
	140375998953168 [label=AccumulateGrad]
	140375998953360 -> 140375998954800
	140375998953504 -> 140375998953744
	140375998386480 [label="upblocks.1.2.bn1.weight
 (128)" fillcolor=lightblue]
	140375998386480 -> 140375998953504
	140375998953504 [label=AccumulateGrad]
	140375998953552 -> 140375998953744
	140375998386640 [label="upblocks.1.2.bn1.bias
 (128)" fillcolor=lightblue]
	140375998386640 -> 140375998953552
	140375998953552 [label=AccumulateGrad]
	140375998953984 -> 140375998954176
	140375998387040 [label="upblocks.1.2.conv1.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998387040 -> 140375998953984
	140375998953984 [label=AccumulateGrad]
	140375998954128 -> 140375998954320
	140375998386960 [label="upblocks.1.2.bn2.weight
 (128)" fillcolor=lightblue]
	140375998386960 -> 140375998954128
	140375998954128 [label=AccumulateGrad]
	140375998954464 -> 140375998954320
	140375998387120 [label="upblocks.1.2.bn2.bias
 (128)" fillcolor=lightblue]
	140375998387120 -> 140375998954464
	140375998954464 [label=AccumulateGrad]
	140375998954560 -> 140375998954656
	140375998387520 [label="upblocks.1.2.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998387520 -> 140375998954560
	140375998954560 [label=AccumulateGrad]
	140375998954800 -> 140375998873024
	140375998954896 -> 140375998955328
	140375998387440 [label="upblocks.1.3.bn1.weight
 (128)" fillcolor=lightblue]
	140375998387440 -> 140375998954896
	140375998954896 [label=AccumulateGrad]
	140375998955184 -> 140375998955328
	140375998387600 [label="upblocks.1.3.bn1.bias
 (128)" fillcolor=lightblue]
	140375998387600 -> 140375998955184
	140375998955184 [label=AccumulateGrad]
	140375998739408 -> 140375998741184
	140375998388000 [label="upblocks.1.3.conv1.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998388000 -> 140375998739408
	140375998739408 [label=AccumulateGrad]
	140375998738736 -> 140375998742432
	140375998387920 [label="upblocks.1.3.bn2.weight
 (128)" fillcolor=lightblue]
	140375998387920 -> 140375998738736
	140375998738736 [label=AccumulateGrad]
	140375998739120 -> 140375998742432
	140375998388080 [label="upblocks.1.3.bn2.bias
 (128)" fillcolor=lightblue]
	140375998388080 -> 140375998739120
	140375998739120 [label=AccumulateGrad]
	140375998872688 -> 140375998869952
	140375998388480 [label="upblocks.1.3.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998388480 -> 140375998872688
	140375998872688 [label=AccumulateGrad]
	140375998873024 -> 140375998869568
	140375998871968 -> 140375998873312
	140375998388560 [label="upblocks.2.0.bn1.weight
 (192)" fillcolor=lightblue]
	140375998388560 -> 140375998871968
	140375998871968 [label=AccumulateGrad]
	140375998873408 -> 140375998873312
	140375998388640 [label="upblocks.2.0.bn1.bias
 (192)" fillcolor=lightblue]
	140375998388640 -> 140375998873408
	140375998873408 [label=AccumulateGrad]
	140375998873552 -> 140374603318656
	140375998389040 [label="upblocks.2.0.conv1.weight
 (64, 192, 3, 3, 3)" fillcolor=lightblue]
	140375998389040 -> 140375998873552
	140375998873552 [label=AccumulateGrad]
	140374639417952 -> 140374603238464
	140375998388960 [label="upblocks.2.0.bn2.weight
 (64)" fillcolor=lightblue]
	140375998388960 -> 140374639417952
	140374639417952 [label=AccumulateGrad]
	140374615767840 -> 140374603238464
	140375998389120 [label="upblocks.2.0.bn2.bias
 (64)" fillcolor=lightblue]
	140375998389120 -> 140374615767840
	140374615767840 [label=AccumulateGrad]
	140374643879456 -> 140374644167776
	140375998389520 [label="upblocks.2.0.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998389520 -> 140374643879456
	140374643879456 [label=AccumulateGrad]
	140374644061280 -> 140374602503840
	140374644061280 [label=ConvolutionBackward0]
	140375998871248 -> 140374644061280
	140374640194464 -> 140374644061280
	140375998388400 [label="upblocks.2.0.downsample.weight
 (64, 192, 1, 1, 1)" fillcolor=lightblue]
	140375998388400 -> 140374640194464
	140374640194464 [label=AccumulateGrad]
	140374602503888 -> 140374602502592
	140375998389440 [label="upblocks.2.1.bn1.weight
 (64)" fillcolor=lightblue]
	140375998389440 -> 140374602503888
	140374602503888 [label=AccumulateGrad]
	140374602504608 -> 140374602502592
	140375998389600 [label="upblocks.2.1.bn1.bias
 (64)" fillcolor=lightblue]
	140375998389600 -> 140374602504608
	140374602504608 [label=AccumulateGrad]
	140374602504416 -> 140374602505472
	140375998390000 [label="upblocks.2.1.conv1.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998390000 -> 140374602504416
	140374602504416 [label=AccumulateGrad]
	140374602504848 -> 140374602502304
	140375998389920 [label="upblocks.2.1.bn2.weight
 (64)" fillcolor=lightblue]
	140375998389920 -> 140374602504848
	140374602504848 [label=AccumulateGrad]
	140374602503360 -> 140374602502304
	140375998390080 [label="upblocks.2.1.bn2.bias
 (64)" fillcolor=lightblue]
	140375998390080 -> 140374602503360
	140374602503360 [label=AccumulateGrad]
	140374602504800 -> 140374602503984
	140375998472496 [label="upblocks.2.1.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998472496 -> 140374602504800
	140374602504800 [label=AccumulateGrad]
	140374602503840 -> 140374603185840
	140374602503456 -> 140374602503744
	140375998472416 [label="upblocks.2.2.bn1.weight
 (64)" fillcolor=lightblue]
	140375998472416 -> 140374602503456
	140374602503456 [label=AccumulateGrad]
	140374602505232 -> 140374602503744
	140375998472576 [label="upblocks.2.2.bn1.bias
 (64)" fillcolor=lightblue]
	140375998472576 -> 140374602505232
	140374602505232 [label=AccumulateGrad]
	140374602504656 -> 140374602505424
	140375998472976 [label="upblocks.2.2.conv1.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998472976 -> 140374602504656
	140374602504656 [label=AccumulateGrad]
	140374602504320 -> 140374602502256
	140375998472896 [label="upblocks.2.2.bn2.weight
 (64)" fillcolor=lightblue]
	140375998472896 -> 140374602504320
	140374602504320 [label=AccumulateGrad]
	140374602505520 -> 140374602502256
	140375998473056 [label="upblocks.2.2.bn2.bias
 (64)" fillcolor=lightblue]
	140375998473056 -> 140374602505520
	140374602505520 [label=AccumulateGrad]
	140374602505760 -> 140374603185360
	140375998473456 [label="upblocks.2.2.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998473456 -> 140374602505760
	140374602505760 [label=AccumulateGrad]
	140374603185840 -> 140374603184496
	140374603183104 -> 140374603182864
	140375998473376 [label="last_bn.weight
 (64)" fillcolor=lightblue]
	140375998473376 -> 140374603183104
	140374603183104 [label=AccumulateGrad]
	140374603184064 -> 140374603182864
	140375998473536 [label="last_bn.bias
 (64)" fillcolor=lightblue]
	140375998473536 -> 140374603184064
	140374603184064 [label=AccumulateGrad]
	140374603182144 -> 140374603185264
	140375998473856 [label="last_layer.weight
 (2, 64, 1, 1, 1)" fillcolor=lightblue]
	140375998473856 -> 140374603182144
	140374603182144 [label=AccumulateGrad]
	140374603185264 -> 140375998933728
}

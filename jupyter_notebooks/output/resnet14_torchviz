digraph {
	graph [size="93.14999999999999,93.14999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140375998955664 [label="
 (2, 2, 17, 128, 128)" fillcolor=darkolivegreen1]
	140375998741232 [label=ConvolutionBackward0]
	140375998741040 -> 140375998741232
	140375998741040 [label=ReluBackward0]
	140375998741568 -> 140375998741040
	140375998741568 [label=NativeBatchNormBackward0]
	140375998740800 -> 140375998741568
	140375998740800 [label=AddBackward0]
	140375998742432 -> 140375998740800
	140375998742432 [label=ConvolutionBackward0]
	140375998741136 -> 140375998742432
	140375998741136 [label=ReluBackward0]
	140375998740608 -> 140375998741136
	140375998740608 [label=NativeBatchNormBackward0]
	140375998740848 -> 140375998740608
	140375998740848 [label=ConvolutionBackward0]
	140375998739264 -> 140375998740848
	140375998739264 [label=ReluBackward0]
	140375998740656 -> 140375998739264
	140375998740656 [label=NativeBatchNormBackward0]
	140375998738880 -> 140375998740656
	140375998738880 [label=AddBackward0]
	140375998739216 -> 140375998738880
	140375998739216 [label=ConvolutionBackward0]
	140375998739648 -> 140375998739216
	140375998739648 [label=ReluBackward0]
	140375998740416 -> 140375998739648
	140375998740416 [label=NativeBatchNormBackward0]
	140375998740704 -> 140375998740416
	140375998740704 [label=ConvolutionBackward0]
	140375998739600 -> 140375998740704
	140375998739600 [label=ReluBackward0]
	140375998739792 -> 140375998739600
	140375998739792 [label=NativeBatchNormBackward0]
	140375998741424 -> 140375998739792
	140375998741424 [label=CatBackward0]
	140375998739120 -> 140375998741424
	140375998739120 [label=AddBackward0]
	140375998740464 -> 140375998739120
	140375998740464 [label=ConvolutionBackward0]
	140375998738688 -> 140375998740464
	140375998738688 [label=ReluBackward0]
	140375998740368 -> 140375998738688
	140375998740368 [label=NativeBatchNormBackward0]
	140375998742480 -> 140375998740368
	140375998742480 [label=ConvolutionBackward0]
	140375998955136 -> 140375998742480
	140375998955136 [label=ReluBackward0]
	140375998952640 -> 140375998955136
	140375998952640 [label=NativeBatchNormBackward0]
	140375998741856 -> 140375998952640
	140375998741856 [label=AddBackward0]
	140375998952352 -> 140375998741856
	140375998952352 [label=ConvolutionBackward0]
	140375998952064 -> 140375998952352
	140375998952064 [label=ReluBackward0]
	140375998952688 -> 140375998952064
	140375998952688 [label=NativeBatchNormBackward0]
	140375998952496 -> 140375998952688
	140375998952496 [label=ConvolutionBackward0]
	140375998952832 -> 140375998952496
	140375998952832 [label=ReluBackward0]
	140375998953264 -> 140375998952832
	140375998953264 [label=NativeBatchNormBackward0]
	140375998953936 -> 140375998953264
	140374603039104 [label="downblocks.0.0.bn1.weight
 (1)" fillcolor=lightblue]
	140374603039104 -> 140375998953936
	140375998953936 [label=AccumulateGrad]
	140375998953984 -> 140375998953264
	140375998984256 [label="downblocks.0.0.bn1.bias
 (1)" fillcolor=lightblue]
	140375998984256 -> 140375998953984
	140375998953984 [label=AccumulateGrad]
	140375998953072 -> 140375998952496
	140375998984896 [label="downblocks.0.0.conv1.weight
 (64, 1, 3, 3, 3)" fillcolor=lightblue]
	140375998984896 -> 140375998953072
	140375998953072 [label=AccumulateGrad]
	140375998952976 -> 140375998952688
	140375998984816 [label="downblocks.0.0.bn2.weight
 (64)" fillcolor=lightblue]
	140375998984816 -> 140375998952976
	140375998952976 [label=AccumulateGrad]
	140375998952160 -> 140375998952688
	140375998984736 [label="downblocks.0.0.bn2.bias
 (64)" fillcolor=lightblue]
	140375998984736 -> 140375998952160
	140375998952160 [label=AccumulateGrad]
	140375998952016 -> 140375998952352
	140375998985296 [label="downblocks.0.0.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998985296 -> 140375998952016
	140375998952016 [label=AccumulateGrad]
	140375998952400 -> 140375998741856
	140375998952400 [label=ConvolutionBackward0]
	140375998952544 -> 140375998952400
	140374603040064 [label="downblocks.0.0.downsample.weight
 (64, 1, 1, 1, 1)" fillcolor=lightblue]
	140374603040064 -> 140375998952544
	140375998952544 [label=AccumulateGrad]
	140375998954368 -> 140375998952640
	140375998985056 [label="downblocks.0.1.bn1.weight
 (64)" fillcolor=lightblue]
	140375998985056 -> 140375998954368
	140375998954368 [label=AccumulateGrad]
	140375998952256 -> 140375998952640
	140375998985376 [label="downblocks.0.1.bn1.bias
 (64)" fillcolor=lightblue]
	140375998985376 -> 140375998952256
	140375998952256 [label=AccumulateGrad]
	140375998951488 -> 140375998742480
	140375998985936 [label="downblocks.0.1.conv1.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998985936 -> 140375998951488
	140375998951488 [label=AccumulateGrad]
	140375998740752 -> 140375998740368
	140375998985856 [label="downblocks.0.1.bn2.weight
 (64)" fillcolor=lightblue]
	140375998985856 -> 140375998740752
	140375998740752 [label=AccumulateGrad]
	140375998738784 -> 140375998740368
	140375998985696 [label="downblocks.0.1.bn2.bias
 (64)" fillcolor=lightblue]
	140375998985696 -> 140375998738784
	140375998738784 [label=AccumulateGrad]
	140375998741712 -> 140375998740464
	140375998986416 [label="downblocks.0.1.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998986416 -> 140375998741712
	140375998741712 [label=AccumulateGrad]
	140375998741856 -> 140375998739120
	140375998739552 -> 140375998741424
	140375998739552 [label=UpsampleTrilinear3DBackward1]
	140375998739840 -> 140375998739552
	140375998739840 [label=AddBackward0]
	140375998739456 -> 140375998739840
	140375998739456 [label=ConvolutionBackward0]
	140375998953552 -> 140375998739456
	140375998953552 [label=ReluBackward0]
	140375998952304 -> 140375998953552
	140375998952304 [label=NativeBatchNormBackward0]
	140375998953840 -> 140375998952304
	140375998953840 [label=ConvolutionBackward0]
	140375998953888 -> 140375998953840
	140375998953888 [label=ReluBackward0]
	140375998954320 -> 140375998953888
	140375998954320 [label=NativeBatchNormBackward0]
	140375998953504 -> 140375998954320
	140375998953504 [label=AddBackward0]
	140375998954176 -> 140375998953504
	140375998954176 [label=ConvolutionBackward0]
	140375998954848 -> 140375998954176
	140375998954848 [label=ReluBackward0]
	140375998954464 -> 140375998954848
	140375998954464 [label=NativeBatchNormBackward0]
	140375998954560 -> 140375998954464
	140375998954560 [label=ConvolutionBackward0]
	140375998955424 -> 140375998954560
	140375998955424 [label=ReluBackward0]
	140375998954992 -> 140375998955424
	140375998954992 [label=NativeBatchNormBackward0]
	140375998955040 -> 140375998954992
	140375998955040 [label=CatBackward0]
	140375998955376 -> 140375998955040
	140375998955376 [label=AddBackward0]
	140375998951728 -> 140375998955376
	140375998951728 [label=ConvolutionBackward0]
	140375998951776 -> 140375998951728
	140375998951776 [label=ReluBackward0]
	140375998951584 -> 140375998951776
	140375998951584 [label=NativeBatchNormBackward0]
	140375998954608 -> 140375998951584
	140375998954608 [label=ConvolutionBackward0]
	140375998953408 -> 140375998954608
	140375998953408 [label=ReluBackward0]
	140375998952448 -> 140375998953408
	140375998952448 [label=NativeBatchNormBackward0]
	140375998955472 -> 140375998952448
	140375998955472 [label=AddBackward0]
	140374603166576 -> 140375998955472
	140374603166576 [label=ConvolutionBackward0]
	140374603166096 -> 140374603166576
	140374603166096 [label=ReluBackward0]
	140374603166336 -> 140374603166096
	140374603166336 [label=NativeBatchNormBackward0]
	140374603166624 -> 140374603166336
	140374603166624 [label=ConvolutionBackward0]
	140374603166912 -> 140374603166624
	140374603166912 [label=ReluBackward0]
	140374603167776 -> 140374603166912
	140374603167776 [label=NativeBatchNormBackward0]
	140375998739120 -> 140374603167776
	140374603167104 -> 140374603167776
	140375998986336 [label="downblocks.1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140375998986336 -> 140374603167104
	140374603167104 [label=AccumulateGrad]
	140374603167056 -> 140374603167776
	140375998986256 [label="downblocks.1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140375998986256 -> 140374603167056
	140374603167056 [label=AccumulateGrad]
	140374603166816 -> 140374603166624
	140375998987296 [label="downblocks.1.0.conv1.weight
 (128, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998987296 -> 140374603166816
	140374603166816 [label=AccumulateGrad]
	140374603166432 -> 140374603166336
	140375998986976 [label="downblocks.1.0.bn2.weight
 (128)" fillcolor=lightblue]
	140375998986976 -> 140374603166432
	140374603166432 [label=AccumulateGrad]
	140374603166960 -> 140374603166336
	140375998987456 [label="downblocks.1.0.bn2.bias
 (128)" fillcolor=lightblue]
	140375998987456 -> 140374603166960
	140374603166960 [label=AccumulateGrad]
	140374603166144 -> 140374603166576
	140375998987856 [label="downblocks.1.0.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998987856 -> 140374603166144
	140374603166144 [label=AccumulateGrad]
	140374603167920 -> 140375998955472
	140374603167920 [label=ConvolutionBackward0]
	140375998739120 -> 140374603167920
	140374603167248 -> 140374603167920
	140375998986176 [label="downblocks.1.0.downsample.weight
 (128, 64, 1, 1, 1)" fillcolor=lightblue]
	140375998986176 -> 140374603167248
	140374603167248 [label=AccumulateGrad]
	140374603584128 -> 140375998952448
	140375998987936 [label="downblocks.1.1.bn1.weight
 (128)" fillcolor=lightblue]
	140375998987936 -> 140374603584128
	140374603584128 [label=AccumulateGrad]
	140375998951680 -> 140375998952448
	140375998988096 [label="downblocks.1.1.bn1.bias
 (128)" fillcolor=lightblue]
	140375998988096 -> 140375998951680
	140375998951680 [label=AccumulateGrad]
	140375998952208 -> 140375998954608
	140375999013168 [label="downblocks.1.1.conv1.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375999013168 -> 140375998952208
	140375998952208 [label=AccumulateGrad]
	140375998952784 -> 140375998951584
	140375999013008 [label="downblocks.1.1.bn2.weight
 (128)" fillcolor=lightblue]
	140375999013008 -> 140375998952784
	140375998952784 [label=AccumulateGrad]
	140375998952592 -> 140375998951584
	140375999013648 [label="downblocks.1.1.bn2.bias
 (128)" fillcolor=lightblue]
	140375999013648 -> 140375998952592
	140375998952592 [label=AccumulateGrad]
	140375998951536 -> 140375998951728
	140375999013728 [label="downblocks.1.1.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375999013728 -> 140375998951536
	140375998951536 [label=AccumulateGrad]
	140375998955472 -> 140375998955376
	140375998955328 -> 140375998955040
	140375998955328 [label=UpsampleTrilinear3DBackward1]
	140375998953168 -> 140375998955328
	140375998953168 [label=AddBackward0]
	140375998951872 -> 140375998953168
	140375998951872 [label=ConvolutionBackward0]
	140375998954656 -> 140375998951872
	140375998954656 [label=ReluBackward0]
	140374603166384 -> 140375998954656
	140374603166384 [label=NativeBatchNormBackward0]
	140374603166864 -> 140374603166384
	140374603166864 [label=ConvolutionBackward0]
	140374603167488 -> 140374603166864
	140374603167488 [label=ReluBackward0]
	140374603167728 -> 140374603167488
	140374603167728 [label=NativeBatchNormBackward0]
	140375998951968 -> 140374603167728
	140375998951968 [label=AddBackward0]
	140374603168400 -> 140375998951968
	140374603168400 [label=ConvolutionBackward0]
	140374603168544 -> 140374603168400
	140374603168544 [label=ReluBackward0]
	140374603166288 -> 140374603168544
	140374603166288 [label=NativeBatchNormBackward0]
	140374603168688 -> 140374603166288
	140374603168688 [label=ConvolutionBackward0]
	140374603168928 -> 140374603168688
	140374603168928 [label=ReluBackward0]
	140374603169168 -> 140374603168928
	140374603169168 [label=NativeBatchNormBackward0]
	140374603169264 -> 140374603169168
	140374603169264 [label=CatBackward0]
	140374603169072 -> 140374603169264
	140374603169072 [label=AddBackward0]
	140374603168208 -> 140374603169072
	140374603168208 [label=ConvolutionBackward0]
	140374603167344 -> 140374603168208
	140374603167344 [label=ReluBackward0]
	140374603168784 -> 140374603167344
	140374603168784 [label=NativeBatchNormBackward0]
	140374603169744 -> 140374603168784
	140374603169744 [label=ConvolutionBackward0]
	140374603168304 -> 140374603169744
	140374603168304 [label=ReluBackward0]
	140374602521952 -> 140374603168304
	140374602521952 [label=NativeBatchNormBackward0]
	140374603168736 -> 140374602521952
	140374603168736 [label=AddBackward0]
	140374602522432 -> 140374603168736
	140374602522432 [label=ConvolutionBackward0]
	140374602519888 -> 140374602522432
	140374602519888 [label=ReluBackward0]
	140374602522288 -> 140374602519888
	140374602522288 [label=NativeBatchNormBackward0]
	140374602521904 -> 140374602522288
	140374602521904 [label=ConvolutionBackward0]
	140374602521472 -> 140374602521904
	140374602521472 [label=ReluBackward0]
	140374602521184 -> 140374602521472
	140374602521184 [label=NativeBatchNormBackward0]
	140375998955376 -> 140374602521184
	140374602521040 -> 140374602521184
	140375999013968 [label="downblocks.2.0.bn1.weight
 (128)" fillcolor=lightblue]
	140375999013968 -> 140374602521040
	140374602521040 [label=AccumulateGrad]
	140374602521088 -> 140374602521184
	140375999014128 [label="downblocks.2.0.bn1.bias
 (128)" fillcolor=lightblue]
	140375999014128 -> 140374602521088
	140374602521088 [label=AccumulateGrad]
	140374602521520 -> 140374602521904
	140375999014768 [label="downblocks.2.0.conv1.weight
 (256, 128, 3, 3, 3)" fillcolor=lightblue]
	140375999014768 -> 140374602521520
	140374602521520 [label=AccumulateGrad]
	140374602522144 -> 140374602522288
	140375999014368 [label="downblocks.2.0.bn2.weight
 (256)" fillcolor=lightblue]
	140375999014368 -> 140374602522144
	140374602522144 [label=AccumulateGrad]
	140374602522576 -> 140374602522288
	140375999015088 [label="downblocks.2.0.bn2.bias
 (256)" fillcolor=lightblue]
	140375999015088 -> 140374602522576
	140374602522576 [label=AccumulateGrad]
	140374602521232 -> 140374602522432
	140375999015488 [label="downblocks.2.0.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375999015488 -> 140374602521232
	140374602521232 [label=AccumulateGrad]
	140374602521664 -> 140374603168736
	140374602521664 [label=ConvolutionBackward0]
	140375998955376 -> 140374602521664
	140374602521856 -> 140374602521664
	140375999013808 [label="downblocks.2.0.downsample.weight
 (256, 128, 1, 1, 1)" fillcolor=lightblue]
	140375999013808 -> 140374602521856
	140374602521856 [label=AccumulateGrad]
	140374602520992 -> 140374602521952
	140375999015408 [label="downblocks.2.1.bn1.weight
 (256)" fillcolor=lightblue]
	140375999015408 -> 140374602520992
	140374602520992 [label=AccumulateGrad]
	140374602522048 -> 140374602521952
	140375999015568 [label="downblocks.2.1.bn1.bias
 (256)" fillcolor=lightblue]
	140375999015568 -> 140374602522048
	140374602522048 [label=AccumulateGrad]
	140374603168352 -> 140374603169744
	140375999015968 [label="downblocks.2.1.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375999015968 -> 140374603168352
	140374603168352 [label=AccumulateGrad]
	140374603167392 -> 140374603168784
	140375999015888 [label="downblocks.2.1.bn2.weight
 (256)" fillcolor=lightblue]
	140375999015888 -> 140374603167392
	140374603167392 [label=AccumulateGrad]
	140374603169552 -> 140374603168784
	140375999016048 [label="downblocks.2.1.bn2.bias
 (256)" fillcolor=lightblue]
	140375999016048 -> 140374603169552
	140374603169552 [label=AccumulateGrad]
	140374603167296 -> 140374603168208
	140375999016448 [label="downblocks.2.1.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375999016448 -> 140374603167296
	140374603167296 [label=AccumulateGrad]
	140374603168736 -> 140374603169072
	140374603169504 -> 140374603169264
	140374603169504 [label=UpsampleTrilinear3DBackward1]
	140374603169648 -> 140374603169504
	140374603169648 [label=AddBackward0]
	140374603166240 -> 140374603169648
	140374603166240 [label=ConvolutionBackward0]
	140374602521808 -> 140374603166240
	140374602521808 [label=ReluBackward0]
	140374602522384 -> 140374602521808
	140374602522384 [label=NativeBatchNormBackward0]
	140374602521424 -> 140374602522384
	140374602521424 [label=ConvolutionBackward0]
	140374602520368 -> 140374602521424
	140374602520368 [label=ReluBackward0]
	140374602520032 -> 140374602520368
	140374602520032 [label=NativeBatchNormBackward0]
	140374603168592 -> 140374602520032
	140374603168592 [label=AddBackward0]
	140374602519648 -> 140374603168592
	140374602519648 [label=ConvolutionBackward0]
	140374602519408 -> 140374602519648
	140374602519408 [label=ReluBackward0]
	140374602522480 -> 140374602519408
	140374602522480 [label=NativeBatchNormBackward0]
	140374602519120 -> 140374602522480
	140374602519120 [label=ConvolutionBackward0]
	140374602518784 -> 140374602519120
	140374602518784 [label=ReluBackward0]
	140374602518688 -> 140374602518784
	140374602518688 [label=NativeBatchNormBackward0]
	140374603169072 -> 140374602518688
	140374602520608 -> 140374602518688
	140375999016528 [label="downblocks.3.0.bn1.weight
 (256)" fillcolor=lightblue]
	140375999016528 -> 140374602520608
	140374602520608 [label=AccumulateGrad]
	140374602520560 -> 140374602518688
	140374603039584 [label="downblocks.3.0.bn1.bias
 (256)" fillcolor=lightblue]
	140374603039584 -> 140374602520560
	140374602520560 [label=AccumulateGrad]
	140374602518976 -> 140374602519120
	140374603442912 [label="downblocks.3.0.conv1.weight
 (512, 256, 3, 3, 3)" fillcolor=lightblue]
	140374603442912 -> 140374602518976
	140374602518976 [label=AccumulateGrad]
	140374602519216 -> 140374602522480
	140374602572240 [label="downblocks.3.0.bn2.weight
 (512)" fillcolor=lightblue]
	140374602572240 -> 140374602519216
	140374602519216 [label=AccumulateGrad]
	140374602519360 -> 140374602522480
	140374603441712 [label="downblocks.3.0.bn2.bias
 (512)" fillcolor=lightblue]
	140374603441712 -> 140374602519360
	140374602519360 [label=AccumulateGrad]
	140374602519456 -> 140374602519648
	140375999016768 [label="downblocks.3.0.conv2.weight
 (512, 512, 3, 3, 3)" fillcolor=lightblue]
	140375999016768 -> 140374602519456
	140374602519456 [label=AccumulateGrad]
	140374602519696 -> 140374603168592
	140374602519696 [label=ConvolutionBackward0]
	140374603169072 -> 140374602519696
	140374602519024 -> 140374602519696
	140375999016368 [label="downblocks.3.0.downsample.weight
 (512, 256, 1, 1, 1)" fillcolor=lightblue]
	140375999016368 -> 140374602519024
	140374602519024 [label=AccumulateGrad]
	140374602519792 -> 140374602520032
	140375999016688 [label="downblocks.3.1.bn1.weight
 (512)" fillcolor=lightblue]
	140375999016688 -> 140374602519792
	140374602519792 [label=AccumulateGrad]
	140374602519984 -> 140374602520032
	140375999016848 [label="downblocks.3.1.bn1.bias
 (512)" fillcolor=lightblue]
	140375999016848 -> 140374602519984
	140374602519984 [label=AccumulateGrad]
	140374602520704 -> 140374602521424
	140375999009152 [label="downblocks.3.1.conv1.weight
 (512, 512, 3, 3, 3)" fillcolor=lightblue]
	140375999009152 -> 140374602520704
	140374602520704 [label=AccumulateGrad]
	140374602521376 -> 140374602522384
	140375999009072 [label="downblocks.3.1.bn2.weight
 (512)" fillcolor=lightblue]
	140375999009072 -> 140374602521376
	140374602521376 [label=AccumulateGrad]
	140374602521616 -> 140374602522384
	140375999009392 [label="downblocks.3.1.bn2.bias
 (512)" fillcolor=lightblue]
	140375999009392 -> 140374602521616
	140374602521616 [label=AccumulateGrad]
	140374602522240 -> 140374603166240
	140375999009952 [label="downblocks.3.1.conv2.weight
 (512, 512, 3, 3, 3)" fillcolor=lightblue]
	140375999009952 -> 140374602522240
	140374602522240 [label=AccumulateGrad]
	140374603168592 -> 140374603169648
	140374603169216 -> 140374603169168
	140375999010032 [label="upblocks.0.0.bn1.weight
 (768)" fillcolor=lightblue]
	140375999010032 -> 140374603169216
	140374603169216 [label=AccumulateGrad]
	140374603169120 -> 140374603169168
	140375999010112 [label="upblocks.0.0.bn1.bias
 (768)" fillcolor=lightblue]
	140375999010112 -> 140374603169120
	140374603169120 [label=AccumulateGrad]
	140374603168976 -> 140374603168688
	140375999010512 [label="upblocks.0.0.conv1.weight
 (256, 768, 3, 3, 3)" fillcolor=lightblue]
	140375999010512 -> 140374603168976
	140374603168976 [label=AccumulateGrad]
	140374603169456 -> 140374603166288
	140375999010432 [label="upblocks.0.0.bn2.weight
 (256)" fillcolor=lightblue]
	140375999010432 -> 140374603169456
	140374603169456 [label=AccumulateGrad]
	140374603168496 -> 140374603166288
	140375999010592 [label="upblocks.0.0.bn2.bias
 (256)" fillcolor=lightblue]
	140375999010592 -> 140374603168496
	140374603168496 [label=AccumulateGrad]
	140374603166000 -> 140374603168400
	140375999010992 [label="upblocks.0.0.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375999010992 -> 140374603166000
	140374603166000 [label=AccumulateGrad]
	140374603169600 -> 140375998951968
	140374603169600 [label=ConvolutionBackward0]
	140374603169264 -> 140374603169600
	140374603168880 -> 140374603169600
	140375999009792 [label="upblocks.0.0.downsample.weight
 (256, 768, 1, 1, 1)" fillcolor=lightblue]
	140375999009792 -> 140374603168880
	140374603168880 [label=AccumulateGrad]
	140374603167968 -> 140374603167728
	140375999010912 [label="upblocks.0.1.bn1.weight
 (256)" fillcolor=lightblue]
	140375999010912 -> 140374603167968
	140374603167968 [label=AccumulateGrad]
	140374603167824 -> 140374603167728
	140375999011072 [label="upblocks.0.1.bn1.bias
 (256)" fillcolor=lightblue]
	140375999011072 -> 140374603167824
	140374603167824 [label=AccumulateGrad]
	140374603167872 -> 140374603166864
	140375999011472 [label="upblocks.0.1.conv1.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375999011472 -> 140374603167872
	140374603167872 [label=AccumulateGrad]
	140374603166048 -> 140374603166384
	140375999011392 [label="upblocks.0.1.bn2.weight
 (256)" fillcolor=lightblue]
	140375999011392 -> 140374603166048
	140374603166048 [label=AccumulateGrad]
	140374603166672 -> 140374603166384
	140375999011552 [label="upblocks.0.1.bn2.bias
 (256)" fillcolor=lightblue]
	140375999011552 -> 140374603166672
	140374603166672 [label=AccumulateGrad]
	140375998954896 -> 140375998951872
	140375999011952 [label="upblocks.0.1.conv2.weight
 (256, 256, 3, 3, 3)" fillcolor=lightblue]
	140375999011952 -> 140375998954896
	140375998954896 [label=AccumulateGrad]
	140375998951968 -> 140375998953168
	140375998955184 -> 140375998954992
	140375999012032 [label="upblocks.1.0.bn1.weight
 (384)" fillcolor=lightblue]
	140375999012032 -> 140375998955184
	140375998955184 [label=AccumulateGrad]
	140375998955088 -> 140375998954992
	140375999012112 [label="upblocks.1.0.bn1.bias
 (384)" fillcolor=lightblue]
	140375999012112 -> 140375998955088
	140375998955088 [label=AccumulateGrad]
	140375998953360 -> 140375998954560
	140375999012512 [label="upblocks.1.0.conv1.weight
 (128, 384, 3, 3, 3)" fillcolor=lightblue]
	140375999012512 -> 140375998953360
	140375998953360 [label=AccumulateGrad]
	140375998954512 -> 140375998954464
	140375999012432 [label="upblocks.1.0.bn2.weight
 (128)" fillcolor=lightblue]
	140375999012432 -> 140375998954512
	140375998954512 [label=AccumulateGrad]
	140375998954800 -> 140375998954464
	140375999012592 [label="upblocks.1.0.bn2.bias
 (128)" fillcolor=lightblue]
	140375999012592 -> 140375998954800
	140375998954800 [label=AccumulateGrad]
	140375998953216 -> 140375998954176
	140375998931168 [label="upblocks.1.0.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998931168 -> 140375998953216
	140375998953216 [label=AccumulateGrad]
	140375998954080 -> 140375998953504
	140375998954080 [label=ConvolutionBackward0]
	140375998955040 -> 140375998954080
	140375998954752 -> 140375998954080
	140375999011872 [label="upblocks.1.0.downsample.weight
 (128, 384, 1, 1, 1)" fillcolor=lightblue]
	140375999011872 -> 140375998954752
	140375998954752 [label=AccumulateGrad]
	140375998954128 -> 140375998954320
	140375998931088 [label="upblocks.1.1.bn1.weight
 (128)" fillcolor=lightblue]
	140375998931088 -> 140375998954128
	140375998954128 [label=AccumulateGrad]
	140375998954032 -> 140375998954320
	140375998931248 [label="upblocks.1.1.bn1.bias
 (128)" fillcolor=lightblue]
	140375998931248 -> 140375998954032
	140375998954032 [label=AccumulateGrad]
	140375998953744 -> 140375998953840
	140375998931728 [label="upblocks.1.1.conv1.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998931728 -> 140375998953744
	140375998953744 [label=AccumulateGrad]
	140375998951920 -> 140375998952304
	140375998931568 [label="upblocks.1.1.bn2.weight
 (128)" fillcolor=lightblue]
	140375998931568 -> 140375998951920
	140375998951920 [label=AccumulateGrad]
	140375998952736 -> 140375998952304
	140375998931648 [label="upblocks.1.1.bn2.bias
 (128)" fillcolor=lightblue]
	140375998931648 -> 140375998952736
	140375998952736 [label=AccumulateGrad]
	140375998952928 -> 140375998739456
	140375998932048 [label="upblocks.1.1.conv2.weight
 (128, 128, 3, 3, 3)" fillcolor=lightblue]
	140375998932048 -> 140375998952928
	140375998952928 [label=AccumulateGrad]
	140375998953504 -> 140375998739840
	140375998738592 -> 140375998739792
	140375998932208 [label="upblocks.2.0.bn1.weight
 (192)" fillcolor=lightblue]
	140375998932208 -> 140375998738592
	140375998738592 [label=AccumulateGrad]
	140375998742240 -> 140375998739792
	140375998932288 [label="upblocks.2.0.bn1.bias
 (192)" fillcolor=lightblue]
	140375998932288 -> 140375998742240
	140375998742240 [label=AccumulateGrad]
	140375998738736 -> 140375998740704
	140375998932688 [label="upblocks.2.0.conv1.weight
 (64, 192, 3, 3, 3)" fillcolor=lightblue]
	140375998932688 -> 140375998738736
	140375998738736 [label=AccumulateGrad]
	140375998739360 -> 140375998740416
	140375998932608 [label="upblocks.2.0.bn2.weight
 (64)" fillcolor=lightblue]
	140375998932608 -> 140375998739360
	140375998739360 [label=AccumulateGrad]
	140375998739984 -> 140375998740416
	140375998932768 [label="upblocks.2.0.bn2.bias
 (64)" fillcolor=lightblue]
	140375998932768 -> 140375998739984
	140375998739984 [label=AccumulateGrad]
	140375998740992 -> 140375998739216
	140375998933248 [label="upblocks.2.0.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998933248 -> 140375998740992
	140375998740992 [label=AccumulateGrad]
	140375998740080 -> 140375998738880
	140375998740080 [label=ConvolutionBackward0]
	140375998741424 -> 140375998740080
	140375998741760 -> 140375998740080
	140375998931968 [label="upblocks.2.0.downsample.weight
 (64, 192, 1, 1, 1)" fillcolor=lightblue]
	140375998931968 -> 140375998741760
	140375998741760 [label=AccumulateGrad]
	140375998740128 -> 140375998740656
	140375998933088 [label="upblocks.2.1.bn1.weight
 (64)" fillcolor=lightblue]
	140375998933088 -> 140375998740128
	140375998740128 [label=AccumulateGrad]
	140375998740272 -> 140375998740656
	140375998933168 [label="upblocks.2.1.bn1.bias
 (64)" fillcolor=lightblue]
	140375998933168 -> 140375998740272
	140375998740272 [label=AccumulateGrad]
	140375998740032 -> 140375998740848
	140375998933888 [label="upblocks.2.1.conv1.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998933888 -> 140375998740032
	140375998740032 [label=AccumulateGrad]
	140375998739696 -> 140375998740608
	140375998933808 [label="upblocks.2.1.bn2.weight
 (64)" fillcolor=lightblue]
	140375998933808 -> 140375998739696
	140375998739696 [label=AccumulateGrad]
	140375998740944 -> 140375998740608
	140375998933968 [label="upblocks.2.1.bn2.bias
 (64)" fillcolor=lightblue]
	140375998933968 -> 140375998740944
	140375998740944 [label=AccumulateGrad]
	140375998741280 -> 140375998742432
	140375998934528 [label="upblocks.2.1.conv2.weight
 (64, 64, 3, 3, 3)" fillcolor=lightblue]
	140375998934528 -> 140375998741280
	140375998741280 [label=AccumulateGrad]
	140375998738880 -> 140375998740800
	140375998741664 -> 140375998741568
	140375998934288 [label="last_bn.weight
 (64)" fillcolor=lightblue]
	140375998934288 -> 140375998741664
	140375998741664 [label=AccumulateGrad]
	140375998740896 -> 140375998741568
	140375998934368 [label="last_bn.bias
 (64)" fillcolor=lightblue]
	140375998934368 -> 140375998740896
	140375998740896 [label=AccumulateGrad]
	140375998738832 -> 140375998741232
	140375998955584 [label="last_layer.weight
 (2, 64, 1, 1, 1)" fillcolor=lightblue]
	140375998955584 -> 140375998738832
	140375998738832 [label=AccumulateGrad]
	140375998741232 -> 140375998955664
}
